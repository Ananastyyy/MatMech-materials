# Комбинаторные алгоритмы

# Лекция 1.

### Литература.

1. [Т. Кормен, Ч. Лейзерсон, Р. Ривест, К. Штайн Алгоритмы. Построение и анализ](https://e-maxx.ru/bookz/files/cormen.pdf)
2. [М. Асанов, В. Баранский, В. Расин Дискретная математика: графы, матроиды, алгоритмы.](https://creewick.github.io/study/courses/graphs/book.pdf)

**Определение 1.**
Пара конечных множеств $G = (V, E)$, где $V$ – произвольное множество, а $E$ является подмножеством множества неупорядоченных пар элементов $V$ называется **графом**, то есть, $E ⊂ \{\{v,w\}: v,w ∈ V\}.$
Элементы множества $V$ называются **вершинами графа**, а множества $E$ – **ребрами**.
Если ребро $e = \{v,w\}$, то говорят, что вершины $v$ и $w$, являются его концами и ребро $е$ смежно вершинам $v$ и $w$.

**Определение 2.**
Пара конечных множеств $G = (V,E)$, где $V$ – произвольное множество, а $E$ является подмножеством множества упорядоченных пар элементов $V$ называется **ориентированным графом** (будем говорить **орграф**), то есть,
$E ⊂ \{\{v,w\}: v,w ∈ V\}$.
Напомню, что элементы ориентированного множества в математике записывают в круглых скобках (, ), а неориентированных - в фигурных {, }.
Например, как записывают координаты вектора?
Если ребро $е = (v,w)$, то говорят, что ребро $е$ начинается в вершине $v$ и заканчивается в $w$.

Кроме особо оговоренных случаев, рассматриваются графы без кратных ребер, то есть, имеется только одна пара $\{v,w\}$, если граф неориентированный, или $(v,w)$ – если граф ориентированный. Кроме того, считаем, что в графе нет петель.

**Определение 3.**
Пусть $G$ – граф, и пусть $р = v_0, e_0, v_1,...,v_k$ в которой каждое ребро $e_i = (v_i, v_{i+1})$ будем называть $(v_0,v_k)$ - **цепью**.
**Цикл** - цепь в которой $v_k=v_0$
Если $G$ ориентированный граф, и каждое ребро начинается в вершине $v_i$ и заканчивается в вершине $v_{i+1}$, то такое множество будем называть $(v_0,v_k)$ - **путем.** 
**Контур** - путь в котором $v_k = v_0$.

$n$ - количество вершин, $m$ – количество ребер, то есть, $n = |V|$, $m = |E|$

**Связный граф** - $\forall \ u,\ w \in V$ существует $(v,w)$ – цепь.
**Ацикличный граф** - граф без циклов.

**Определение 4.**
**Дерево** - связный ацикличный граф.

### Теорема 1.

Для графа $G = (V,E)$ следующие условия эквивалентны
1. $G$ – дерево.
2. Для любых вершин v и w существует единственная $(v,w)$ - цепь.
3. Граф $G$ связен и $m = n - 1$.
4. Граф $G$ ацикличен и $m = n – 1$.
5. Добавление в граф любого нового ребра приводит к появлению ровно одного цикла.

## Способы представления графов в компьютере.

### Для неориентированного графа.

- Матрица смежности
    
    Определяется как матрица $А$ размера $n*n$, все элементы которой равны или 0 или 1, при этом $А[v,w] = 1 \Leftrightarrow$  ребро $\{v,w\}$ имеется в графе.
    
- Списки смежностей
    
    Заводится $n$ списков по одному для каждой вершины графа $v$. Каждая запись в списке содержит два поля. В первом поле указывается очередная вершина смежная данной, то есть, смежная $v$, во втором – ссылка на следующую запись. В последней записи указатель на конец списка. Чтобы вся эта конструкция работала необходим еще один список, обычно одномерный массив длины $n$, на $i$ – месте стоит адрес первой записи списка отвечающего вершине $i$.
    
- Массив смежностей
    
    Представляет собой все списки смежностей, упакованные в один массив. За счет этого экономится память, так как не хранится ссылка на следующую запись. 
    
    Заводится одномерный массив $А$ длины $n + 2m$.
    
    По адресу $i = 1,…,n$ стоит первая вершина, смежная вершине $i$, далее от  $А[i] + 1$ до $А[i + 1]$ перечисляются все вершины смежные с $i$.
    
    Почему получается массив длины $n + 2m$? Просто потому что, каждое ребро $\{v,w\}$ записывается дважды, вершиной $w$, смежной с $v$, и вершиной $v$, смежной с $w$.
    

$$\begin{array}{|c | c |c | c|}\hline$
$\text{} & \text{ Потребляемая память } & \text{Посчитать степень вершины} & \text{Добавить/удалить ребро} \\\hline$
$Матрица &n^2 &O(n) &O(1) \\\hline$
$Списки &n + 4m &O(n)\ или\ O(m) &O(1) \\\hline$
$Массив &n+2m &O(1) &невозможно\\\hline$
$\end{array}$$

### Для ориентированного графа.

Матрица смежностей меняется очевидным образом.
Для описания графа, заданного списками смежностей, обычно используется два списка $СЛЕД$, в котором, для каждой вершины $v$ перечисляются вершины в которые идут ребра из $v$, и $ПРЕД$ – из которых идут ребра в вершину $v$. Естественно, что для описания графа достаточно для каждой вершины хранить только один из списков $ПРЕД$ или $СЛЕД$, но зачаcтую удобнее хранить оба, более того считать, что каждая запись в списках содержит три поля, в добавленном хранить ссылку на ребро, которое есть в другой записи.
Теперь несложно упаковать списки в один массив и получить представление ориентированного графа массивом.

# Лекция 2.

## Поиск в графе.

### Задача.

Требуется обойти вершины, до которых существует цепь из заданной вершины.

Заведем структуру $СПИСОК$, куда будем кидать посещенные вершины. Тот факт, что вершина $v$ посещена из $w$, отмечается обычно так, заводится одномерный массив **ОТЕЦ**, и полагается $ОТЕЦ[v] = w$.

```pascal
1. begin
2.		v → СПСК; ОТЕЦ[v] = nill
3.    while (СПСК ≠ ∅) then
4.    begin w ← СПСК;
5.      if (есть не посещенная вершина u смежная с w) then
6.		    begin u → СПСК; ОТЕЦ[u] = w
7.        end
8.      else ← СПСК
9.    end
10. End
```

Поиск в ширину получается если структура **СПСК** задается как **ОЧЕРЕДЬ**, а поиск в глубину – как **СТЕК**. Буду считать, что **ПВШ** и **ПВГ** вам всем известны. Практически все рассматриваемые в курсе алгоритмы так или иначе используют поиск в графе.
Каждый поиск можно описать двумя правилами
1. Правило вытаскивания очередной вершины их структуры **СПСК**
2. Правило просмотра вершин инцидентных вытащенной.
Например, **ПВШ** получается, если вытаскивается первая добавленная вершина (Правило 1) и посещаются все вершины смежный данной (Правило 2); **ПВГ** получается, если просматривается последняя добавленная.

**Пример.**

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled.png)

Отобразим работу алгоритма в таблице

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%201.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%201.png)

Сложность метода поиска в ширину или в глубину в графе $O(n + m).$

**Комментарий.** 
Имеется ввиду граф, в котором, например, вообще нет ребер, тогда ПВШ придется запускать из каждой вершины (как и ПВГ). Для связного графа оценку можно упростить $O(m)$. Правда надо знать, что $m ≥ n$, для связного графа.

### Теорема.

Для каждой вершины $w$, метод ПВШ строит кратчайшую $(v,w)$ - цепь в графе $G$ (здесь $v$ – корневая вершина поиска)

**Комментарий.** 
Точнее так. Построим дерево поиска на том же множестве вершин, что и в исходном графе. Для каждой вершины $w$, кроме корневой поиска $(w ≠ v)$, выберем ребро $\{ОТЕЦ[w],w\}$. Тогда для каждой пары вершин $v$ и $w$ единственная $(v,w)$ - цепь в дереве поиска является кратчайшей, по числу ребер, цепью в исходном графе.

Чаще всего считают деревья поиска ориентированными, где ориентация ребра идет от вершины $ОТЕЦ[w]$ к $w$.

Тогда последнюю теорему можно сформулировать так.

Для каждой вершины $w$, метод ПВШ строит кратчайший $(v,w)$ - путь в графе $G$.

# Лекция 3.

## Задача о минимальном остове.

**Определение.**
Пусть $G=(V,E,c)$ - взвешенный. $c$ - функция на ребрах.
$G^* = (V^*, E^*, c)$ - остов графа G если
$V^* = V\\ G^* -$  дерево.
$G -$ связен.

### Задача 1.

В заданном, не обязательно взвешенном, графе построить остов.
Метод решения - любой поиск, дерево поиска является остовом, если граф связен.
Сложность $O(m)$ - если связный граф задан списками, 
$O(n^2)$ - если задан матрицей 

### Задача 2.

В заданном связном, взвешенном графе, построить остов минимального веса. 

Если $G^* = (V^*, E^*)$ - остов, то его весом назовем сумму весов входящих в него ребер.
В дальнейшем остов можно отождествлять с множеством входящих в него ребер. Будем обозначать остов буквой  $T$.

**Определение.**
Семейство $r$ подграфов графа $G$, 
$r = \{Г_1=(V_1,E_1),..., Г_к= (V_k,E_k)\}$ называется остовным лесом, если
1.  $Г_i$  – дерево
2.  $V_i \cap V_j = \empty$
3. $\cup \{V_i : i = 1,...,k\} = V$
$r^* = \{(i, \empty ) : i = 1,..., n\} -$  тривиальный лес (из пней).

Ребро $е$ называется внешним к лесу, если оно не входит ни в одно дерево этого леса. Пусть $е$ – внешнее к лесу $r$. Тогда $r$ соединяет деревья $Г_i$ и $Г_j$. Расширением к лесу $r$ по ребру $е$ называется лес, в котором два различных дерева $Г_i$ и $Г_j$  объединены в одно. Обозначать расширение леса будем символом $r(e)$. 
Пусть $С$ – вес минимального остова, а $Сr$ – вес минимального остова, содержащего все ребра леса $r$.

### Утверждение.

$С = Сr^{*}$

Все алгоритмы основаны на следующем утверждении.

### Лемма.

Пусть $r$ остовный лес, $е$ – внешнее к нему ребро, соединяющее деревья $Г_i$ и $Г_j$ и выполняется хотя бы одно из условий
1. $е$ – минимальное внешнее к $Г_i$.
2. $е$ – минимальное внешнее к $Г_j$.
Тогда $Сr = Cr(e)$.

**Доказательство.**
Неравенство $Сr ≤ Cr(e)$ очевидно.
Докажем обратное неравенство.
Требуется доказать, что для любого остова $Т$, содержащего все ребра леса $r$, найдется остов $Т^*$, содержащий все ребра леса $r$ и ребро $е$, такой что $║Т║ ≤ ║Т║$. 
Для определенности будем считать, что выполняется первое утверждение леммы и пусть $е = (v,w),\ v \in Г_i, w \in Г_j$. 
Пусть $Т$ произвольный остов, содержащий все ребра леса $r$. 
Если $Т$ содержит ребро $е$, то достаточно положить $Т^*=Т$ и все доказано.
Пусть $Т$ не содержит ребро $е$. Добавим $е$ к $Т$. Образуется в точности один цикл. Этот цикл содержит ребро $v^*w^*$ внешнее по отношению к дереву $Г_i$. По условию $c(v,w) ≤ c(v^*,w^*)$. Заменим в дереве $Т$ ребро $v^*w^*$ на ребро $vw$. Получим остов, который обозначим $Т^*$. Он искомый. $\square$

### Алгоритм Борувки, Краскла.

1. Пеньковый лес объявить текущим.
2. До тех пор пока текущий лес не сольется в одно дерево, приводить его приращение по минимальному внешнему к лесу ребру.

### Алгоритм Ярника, Прима, Дейкстры.

1. В пеньковом лесу произвольный пень объявить растущим деревом. 
2. До тех пор пока растущее дерево не поглотит все вершины проводить приращение леса по минимальному внешнему к растущему дереву ребру.

Доказательство корректности обоих алгоритмов вытекает из леммы. В самом деле, справедлива цепочка равенств $C = Cr^* = …= Cr$.

# Лекция 4.

## Реализация алгоритмов.

### Алгоритм Борувки, Краскла.

1. Пеньковый лес объявить текущим.
2. До тех пор пока текущий лес не сольется в одно дерево, приводить его приращение по минимальному внешнему к лесу ребру.

Для описания растущего дерева заводится три одномерных массива, каждый длиной $n$: $ИМЯ$, $РАЗМЕР$, $СЛЕД$. 
В каждом дереве текущего леса выбирается вершина $w$, являющаяся именем множества вершин этого дерева, и 
$ИМЯ[v] = w$, для всех вершин $v$. 
$РЗМР[w]$ – количество вершин в дереве с именем $w$. 
На каждом дереве задается кольцевая структур данных для того чтобы быстро пробежать именно по вершинам этого дерева. 
$СЛЕД[v]$ – показывает, вершину следующую за $v$ в этом дереве.

**Пример.**

$$\begin{array}{|c|c|c|c|c|c|c|c|}\hline$
$\text{} &1&2&3&4&5&6&7 \\\hline$
$ИМЯ &2 &2 &2 &2 &* &2 &1 \\\hline$
$РЗМР &* &4 &* &* &6 &6 &7 \\\hline$
$СЛЕД &3 &1 &4 &2 &6 &5 &7 \\\hline$
$\end{array}$$

### Пример слияния деревьев.

Пусть $p = ИМЯ[v]$, $q = ИМЯ[w]$, и $p ≠ q$. Присоединение дерева с именем $q$ к дереву с именем $p$.

```pascal
1. procedure СЛИТЬ (v,w,p,q) 
2. begin 
3. ИМЯ[w] = p, u = СЛЕД[w] 
4. while (ИМЯ[u] ≠ p) do 
5.     begin ИМЯ[u] = p; u = СЛЕД[u] 
6.     end 
7.   РЗМР[p] = РЗМР[p] + РЗМР[q] 
8.   x = СЛЕД[v], y = СЛЕД[w]
9.   СЛЕД[v] = y, СЛЕД[w]= x 
10.end
```

```python
def Merge(v, w, p, q):
    name[w] = p
    u = Next[w]
    while name[u] != p:
        name[u] = p
        u = Next[u]
    size[p] += size[q]
    Next[v], Next[w] = Next[w], Next[v]
```

**Реализация алгоритма.**
Вход: Связный, взвешенный граф $G = (V,E,c)$ 
Выход: минимальный остов $Т$.
Сложность: $O(m\log{m})$.

```pascal
1. begin Отсортировать Е по возрастанию веса. Получить ОЧРД 
2. for v ∈ V do 
3.   begin ИМЯ[v] = v , РЗМР[v] = 1 , СЛЕД [v] = v 
4.   end // создали пеньковый лес
5. T = ∅ 
6. while |T| ≠ n – 1 do
7.   begin
8.     vw ← ОЧРД, ← ОЧРД, p = ИМЯ[v], q = ИМЯ[w] 
9.     if p ≠ q then 
10.      begin 
11.        if РЗМР[p] > РЗМР[q] then СЛИТЬ(v,w,p,q)
12.        else СЛИТЬ(w,v,q,p) 
13.        T = T ∪ vw 
14.      end 
15.    end 
16. end
```

**Алгоритм Борувки, Красклa имеет сложность $O(m\log{m})$.**
Строка 1, где надо упорядочить все ребра, имеет сложность $O(m\log{m})$. 
Пусть вершина $v$ попадает в множества $V_1, V_2,...,V_k$. 
Тогда $|V_1| = 1, |V_2| ≥ 2,...,|V_i| ≥ 2^{i - 1}, |V_k| = n$. 
Множества $V_i$ – это множества вершин остовных лесов, а каждая вершина $v$ попадает в $V_i$ только при смене имени. Остается посчитать сколько раз она это делает. 
Справедливо: $n = |V^k| ≥ 2^{k – 1}$. Отсюда $k ≤ 1 + \log{n}$. 
Следовательно, смена имени требует $O(n\log{n})$ операций поскольку в графе $n$ вершин и при смене имени имя меняется только у меньшего множества. 
Тогда сложность всего алгоритма
$O(m\log{m}) + O(n\log{n}) = O(m\log{m})$, так как связность графа влечет справедливость неравенств $n – 1 ≤ m ≤ n^2$. $\square$

### Алгоритм Ярник, Прим, Дейкстра.

1. В пеньковом лесу произвольный пень объявить растущим деревом.
2. До тех пор пока растущее дерево не поглотит все вершины проводить приращение леса по минимальному внешнему к растущему дереву ребру.

При незатейливой реализации этого алгоритма легко получить сложность $O(n^3)$.

Пусть $Р$ – вершины, уже включенные в текущее дерево. 
Поначалу $Р = \{v\}$, где вершина $v$ - тот самый пень, который объявлен растущим. 
Заведем два одномерных массива $БЛИЖН$ и $D$, где для любой вершины $w$, не лежащей в $Р$, значение $БЛИЖН[w]$ дает имя той вершины в $Р$ ближе всего расположенной к $w$, то есть, 
$с(w, БЛИЖН[w]) ≤ c(w,u)$, $\forall u \in Р$. 
(т.е., $БЛИЖН[w]$ – проекция $w$ на $Р$) и
$D[w] = c(w,БЛИЖН[w])$ – длина этой проекции.

**Реализация алгоритма Ярник, Прим, Дейкстра.**

```pascal
1. begin 
2. v – произвольно из V, W = V \ {v}, T = ∅
3. for w ∈ W do 
4.   begin БЛИЖН[w] = v, D[w] = c(w,v) 
5.   end 
6. while (|T| < n – 1) do // T = ∅
7.   begin w = Min(W), T = T ∪ w ∪ БЛИЖН[w], W = W\w 
8.     for u ∈ W do 
9.       begin 
10.        if c(w,u) < D[u] then 
11.        begin БЛИЖН[u] = w, D[u] = c(w,u) 
12.        end
13.      end 
14.   end 
15. end
```

```python
w = # произвольная веришна из V
W = V.remove(v)
T = []
for v in V:
    near[v] = w
    D[w] = c(w, v)
T = []
while len(T) < n - 1:
    w = Min(W)
    u = near[w]
    T.append(w)
    T.append(u)
    W.remove(w)
    for u in W:
        if c(w, u) < D[u]:
            near[u] = w
            D[u] = c(w, u)
```

**Алгоритм Ярник, Прим, Дейкстра имеет сложность $O(n^2)$.**
Цикл в строках 2 – 5 имеет сложность $O(n)$. 
Оценим сложность основного цикла (строки 6 – 13 ). 
Пусть $k$ вершин добавлено в растущее дерево, значит не добавленных остается $n – k$. Выбор минимального элемента (строка 7) требует числа операций пропорционального 
n – k. 
Строки 8 – 13 пропорциональны $n –k – 1$. 
Значит общая сложность алгоритма $\sum( n – k) = O (n^2$). $\square$

### Замечания.

Алгоритм Борувка, Краскл предпочтителен, когда количество ребер в графе не очень большое, т.е. , $m ≈ n$. 
Алгоритм Ярник, Прим, Дейкстра хорошо работает когда ребер много, например, для полных графов.

## Некоторые NP-полные задачи.

**1. Задача о минимальном остове с ограничениями на степень вершин** 
Задан граф $G=(V,E,c)$, и число $k$. Требуется построить минимальный остов так, чтобы $deg(v) ≤ k$. 

**2. Задача Штейнера** 
Задан граф $G=(V,E,c)$ и множество вершин $W$. Требуется построить минимальный (по весу) подграф $Г$ графа $G$, содержащий множество $W$. Задача остается NP-полной даже в том случае, когда вершины графа это точки на плоскости, граф полный, а веса ребер – это просто расстояния между соответствующими вершинами. Такая задача возникает при проектировании РЭА.

# Лекция 5.

## Задачи о кратчайших путях.

Всюду рассматриваются ориентированные взвешенные графы $G=(V,E,c)$. 
«Длину» пути $р$ положим равным $\sum\{c(e): e ∈ p\}$. 
Рассмотрим три задачи. 
1. $1-1$ Для заданных вершин $s$ и $t$ найти кратчайший $(s,t)$ - путь. 
2. $1-\forall$ Найти кратчайшие пути от заданной вершины $s$ до всех остальных вершин сети $G$. 
3. $\forall - \forall$ Найти кратчайшие пути для каждой пары вершин $v$ и $w$ из $G$.

**Пример.**

**Задача проводки платежа.** 
Имея на руках валюту $х$ требуется осуществить платеж в валюте $у$. Построим сеть $G=(V,E,c)$. 
В ней $V$ – множество валют, $i = 1, 2, …, n$. 
$E$ – каждая пара вершин соединена двумя ориентированными ребрами, $c(i,j)$ – количество единиц $j$-валюты приходящихся на 1 единицу $i$-валюты. Пусть $i$ – рубль, $j$ – доллар. Курс Центробанка: 1$ = 73,5 рубля. Но этот курс не интересен, важен обменный 1$ = 72 руб, 1 руб = 0,013$.
В нормальной экономике $с(i,j)*c(j,i) < 1$. 
Вес пути положим равным $∏\{с(e) : e \in p\}$.
Требуется найти наиболее выгодный путь от валюты $х$ к валюте $у$, то есть, найти $(х,у)$ - путь максимального веса.

Покажем, что эта задача сводится к задаче о кратчайшем пути. 
Построим новую сеть, где множества вершин и ребер те же самые, что и в задаче проводки платежа, а новые веса ребер определим по формуле 
$с^*(i, j)=-\log{c(i, j)}$.
Пусть решена задача о кратчайшем пути от $х$ до $у$, то есть, найден $(х,у)$-путь $р$, такой, что сумма весов входящих в него ребер минимальна среди всех $(х,у)$ - путей.
Тогда $\sum{c^*(e): e\in p}\to min \Leftrightarrow \sum\{-\log{c(e): e \in p}\}\to min\\ \Leftrightarrow - \sum\{\log{c(e): e \in p}\}\to min\\ \Leftrightarrow + \sum\{\log{c(e): e \in p}\}\to max\\ \Leftrightarrow \log(∏\{c(e): e \in p\})\to max\\ \Leftrightarrow ∏\{c(e): e \in p\}\to max$

### Замечание.

Все алгоритмы вначале считают расстояния от заданной вершины $s$ до всех остальных (прямой ход), а затем находят нужный путь. То есть, для решения задачи 1 - 1 приходится решать $1-\forall$.

## Общий случай.

Считаем, что в заданной сети нет контуров отрицательной длины, ибо, если такой контур есть, то расстояние между любыми вершинами контура становится неопределенным

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%202.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%202.png)

Вес ребра $(1,2)$ равен 2, а остальных – 1. При переходе к  $(-\log{e})$ получим вес этого ребра отрицателен, а у всех остальных ребер равен нулю.

**Определение.**
$D(k,v)$ – длина пути от $s$ до $v$ среди всех путей, содержащих не более $k$ ребер.

## Алгоритм Форд, Беллман.

Последовательно вычислять $D(k,v)$ для всех $к = 1, 2,..., n-1$ и всех $v$, используя формулы.

$$
\begin{cases}
D(1,v) = c (s,v)\\
D(k+1,v) = min\{D(k,v), D(k,w) + c(w,v)\} : по\ всем\ w \in V, w \neq v \}.\end{cases}
$$

Ответом является $D(n-1,v)$.
Организовать все вычисления можно с помощью одного массива $D$. 
Для удобства сделаем еще структуру $ПРЕД$, 
Где $ПРЕД[v]$ – дает вершину, предпоследнюю в текущем кратчайшем $(s,v)$-пути.

**Реализация алгоритма.**

**Вычисление длины пути от заданной вершины до всех остальных.**
Вход: Сеть $G=(V,E,c)$, заданная матрицей весов А.
Выход: массив расстояний $D$, где $D[v]$ – расcтояние от $s$ до $v$, массив $ПРЕД$, где $ПРЕД[v]$ - предпоследняя вершина в кратчайшем пути от $s$ до $v$.
Сложность: $O(n^3)$.

```pascal
1. begin  D[s] = 0, ПРЕД[s] = 0
2. for v ∈ V\{s} do
3.   begin D[v] = A[s,v], ПРЕД[v] = s
4.   end 
5. for k = 2 to n – 1 do
6.   for v ∈ V\{s} do 
7.     for w ∈ V\{s} do 
8.       if D[w] + A[w,v] < D[v] then 
9.         begin D[v] = D[w] + A[w,v], ПРЕД[v] = w 
10.        end
11. end.
```

```python
D[s] = prev[s] = 0
for v in V.difference(s):
    D[v] = A[s][v]
    prev[v] = s
for k in range(n - 2):
    for v in V.difference(s):
        for w in V: #  в лекциях без s, в учебнике с
            if D[w] + A[w][v] < D[v]:
                D[v] = D[w] + A[w][v]
                prev[v] = w
```

Заметим, что при каждом входе в цикл 5 – 9, выполняются неравенства $d(s,v) ≤ D[v]$, где через $d(s,v)$ – обозначено расстояние от вершины $s$ до $t$. 

### Алгоритм п**остроения пути от заданной вершины до заданной.**

Вход: вершины $s$ и $t$, массивы $D$ и $ПРЕД$.
Выход: $СТЕК$, который определяет кратчайший $(s,t)$ - путь.

```pascal
1. begin 
2. СТЕК = ∅, t → СТЕК, u = ПРЕД[t]
3. while (ПРЕД[u] ≠ 0) do
4.   begin u → СТЕК, u = ПРЕД[u] 
5.   end 
6. s → СТЕК
7. end
```

```python
Stack.push(t)
u = prev[t]
while prev[u] != 0:
    Stack.push(u)
    u = prev[u]
```

**Теорема.**
Алгоритм Форда, Беллмана имеет сложность $O(n^3)$.

# Лекция 6.

## Случай неотрицательных весов.

Рассматривается задача вычисления расстояний от заданной вершины $s$. Через $d(v)$ обозначим расстояние от $s$ до $v$.

### Алгоритм Дейкстры одной фразой.

Последовательно вычислять расстояние до очередной ближайшей к $s$ вершине.

**Как это сделать?**

Ближайшая к $s$ это вершина $s$. То есть, положим $d(s) = 0$. 
Пусть $k$ ближайших к вершин определены и для всех них вычислены расстояния, то есть, определено множество $S=\{v_1=s,v_2,...v_k\}$ и выполнятся неравенства
$1)\ 0 = d(v_1) ≤ d(v_2) ≤ ... ≤ d(v_k)\\2)\ d(v_k) ≤ d(v),\forall v \in F, где\ F = V \setminus S.$

В неравенствах 1) все расстояния вычислены, а в 2) неравенства имеют потенциальный характер.$\\ \forall w \in F,\ положим\ t(w) = min\{d(v_i) + c(v_i,w) : v \in S\}.$$3) w^* \in F\ такая,\ что\ t(w^*)=min\{t(w):w\in F\}$
Оказывается $w^*$ является следующей ближайшей к $s$ вершиной. Точнее справедлива следующая теорема.

### Теорема.

Пусть $k$ ближайших к $s$ вершин определены и вычислены расстояния $d(v_1), d(v_2),...,d(v_k)$ так, что выполняются неравенства 1) и 2). Вершина $w^*$ выбрана с условием 3). Тогда $w^* - (k + 1)$-ая, ближайшая к $s$ и $d(w^*) = t(w^*).$

Пусть $р$ тот самый путь, на котором получается расстояние от вершины $s$ до $w^*$, то есть, $||p|| = d(w^*)$. 
Справедлива цепочка неравенств $||p|| ≤ t(w^*) ≤ t(u) ≤ ||p||$.
Значит $||p|| = t(w^*) = d(w^*)$.
Почему вершина $w^*$ является очередной, ближайшей к $s$? 
Для этого нужно показать, что $d(w^*) ≤ d(w)$,  $\forall w \in F$. 
Фактически, это доказано при рассмотрении предыдущего случая.
Пусть $p^*$ тот самый путь до вершины $w$ на котором достигается расстояние от $s$ до $w$. Справедлива цепочка неравенств
$d(w^*) = t(w^*) ≤ t(u) ≤ ||p^*|| = d(w).$

**Реализация алгоритма.**
**Вычисление расстояний от фиксированной вершины до всех остальных** Вход: сеть $G = (V,E,c)$, заданная неважно как, вершина $s$.
Выход: массивы $D$ и $ПРЕД$, где $D[v]$ – расстояние от $s$ до $v$,
$ПРЕД[v]$ – предыдущая вершина в кратчайшем $(s,v)$-пути.
Сложность: $O(n^2)$.

```pascal
1. begin
2. D[s] = 0, ПРЕД[s] = 0, F = V\{s}
3. for v ∈ F do 
4.   begin D[v] = c(s,v), ПРЕД[v] = s 
5.   end
6. for k = 1 to n - 1 do
7.   begin 
8.     w = min(F), F = F \ {w}
9.     for v ∈ F do 
10.      if  D[w] + c(w,v) < D[v] then
11.        begin  D[v] = D[w] + c(w,v), ПРЕД[v] = w 
12.        end
13.    end 
14. end
```

```python
D[s] = prev[s] = 0
F = V.difference(s)
for v in F:
    D[v] = A[s][v]
    prev[v] = s
for k in range(n - 1):
    w = Min(F)
    F = F.difference(w)
    for v in F:
        if D[w] + A[w][v] < D[v]:
            D[v] = D[w] + A[w][v]
            prev[v] = w
```

```csharp
var visited = new bool[vertCount];
var distance = MemSet(new int[vertCount], int.MaxValue);
var prev = new int[vertCount];

distance[start - 1] = 0;
for (var i = 0; i < vertCount; i++)
{
    var vertex = Min(visited, distance);

    if (vertex == -1)
        continue;

    visited[vertex] = true;
    for (var adjVertex = 0; adjVertex < vertCount; adjVertex++)
    {
        if (adjMatrix[vertex, adjVertex] < 0 || visited[adjVertex]) 
            continue;
        var newKey = adjMatrix[vertex, adjVertex] + distance[vertex];

        if (newKey >= distance[adjVertex]) 
            continue;
        distance[adjVertex] = newKey;
        prev[adjVertex] = vertex + 1;
    }
}

return (distance, prev);
```

**Теорема.**
Алгоритм Дейкстры имеет сложность $O(n^2)$.

### Геометрическая интерпретация алгоритма Дейкстры.

Говорят, что алгоритм Дейкстры строит дерево кратчайших путей.

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%203.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%203.png)

## Случай бесконтурного графа.

Пусть $G = (V,E)$ – бесконтурный граф.

### Лемма 1.

В каждом бесконтурном графе имеется хотя бы одна вершина с нулевой полустепенью исхода и хотя бы одна вершина с нулевой полустепенью захода.

### Лемма 2.

Вершины бесконтурного графа можно перенумеровать так, чтобы каждое ребро исходило из вершины с меньшим номером и входило с большим. **Такую перенумерацию называют топологической сортировкой**.

### Алгоритм топологической сортировки.

1. Наибольшим неиспользованным номером считать $n$ – число вершин в графе. 
2. Выбрать произвольную вершину $v$ с нулевой полустепенью исхода. Присвоить $v$ наибольший из неиспользованных номеров. Номер, который получит вершина $v$ считать использованным.
3. Удалить из графа вершину $v$, вместо со всеми ребрами в неё входящими.
4. Повторять шаги 2. и 3. пока все вершины не получат номер. 
Сложность этого алгоритма $O(m)$.
Асанов, Баранский, Расин стр. 249.

**Реализация алгоритма.**
Вход: бесконтурный орграф, заданный списками смежностей.
Выход: массив $Index$ длины $n$ такой, что для любой дуги $vw \in E$ справедливо неравенство $Index[v] < Index[w]$.
Сложность: $O(m)$.

```python
for v in V:
    DegOut[v] = 0
for v in V:
    for w in List[v]:
        DegOut[w] += 1
Q = Queue()
number = n
for v in V:
    if DegOut[v] = 0:
        Q.enqueue(v)
    while Q:
        v = Q.dequeue()
        Index[v] = number
        number -= 1
        for w in List[v]:
            DegOut[w] -= 1
            if DegOut[w] = 0:
                Q.enqueue(v)
```

### Алгоритм Тарьяна.

1. Все вершины объявить белыми.
2. Пока существуют белые вершины.
3. Выбрать любую из них, перекрасить ее в серый и осуществить ПВГ из нее. По дороге красить все вершины в серый. 
4. Как только у встретившейся вершины все соседи уже посещены, затолкнуть эту вершину в стек и объявить ее черной. 
5. Стек является ответом.

**Реализация алгоритма.**
Вход: бесконтурный орграф.
Выход: каждая вершина получает НОМЕР так, что граф становится топологически отсортированным.

```pascal
1. начало
2. Для всех v ∈ F   положить    НОМЕР[v] = 0, 
3. k = n 
4. До тех пор пока (существует v: НОМЕР[v] = 0)
5.   Осуществить ПВГ(v) двигаясь по вершинам, у которых НОМЕР = -,
6.     Как только все соседи w получили НОМЕР, то 
7.       НОМЕР [w] = k, k = k - 1 
8. конец
```

# Лекция 7.

## Расстояние в бесконтурной сети.

Будем считать, что заданная сеть $G = (V,E,с)$ топологически отсортирована. 
Считаем тогда, что вершины пронумерованы натуральными числами $1, 2,…, n$ и вычисляются расстояния от вершины 1. 
Через $d(i)$ обозначим расстояние от вершины 1 до вершины $i$.

### Алгоритм одной фразой.

Последовательно вычислять расстояния до очередной по номеру вершины, используя формулы
$d(1) = 0\\ 
d(k + 1) = min\{ d(i) + c(i,k+1): (i,k+1) \in E\}$.

### Алгоритм безымянный.

Вход: сеть, заданная списками $СЛЕД$.
Выход: массивы $D$ и $ПРЕД$ такие же как и ранее, то есть
$D[i]$ – расстояние от 1 до $i$, 
$ПРЕД[i]$ – предпоследняя вершина в кратчайшем $(1-i)$ - пути.
Сложность: $O(m)$.

```pascal
1. begin D[1] = 0, ПРЕД[1] = 0
2. for k = 2 to n do
3.   begin D[k] = +∞, ПРЕД[k] = 0
4.   end
5. for k = 1 to n – 1 do 
6.   begin for v ∈ СЛЕД[k] do 
7.     if D[k] + c(k, v) < D[v] then
8.       begin D[v] = D[k] + c(k,v), ПРЕД[v] = k
9.       end
10.  end 
11. end
```

```python
D[1] = 0
prev[1] = 0
for k in range(2, n + 1):
    D[k] = sys.maxsize
		prev[k] = 0
for k in range(1, n):
    for v in List[k]:
        if D[k] + c(k, v) < D[w]:
            D[v] = D[k] + c(k, v)
            prev[v] = k
```

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%204.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%204.png)

> Алгоритм Безымянный имеет сложность $O(m).$
Достаточно заметить, что каждое ребро анализируется ровно один раз и при каждом анализе ребра, число операций ограничено константой.
> 

## Задача о пути максимального веса.

Вес пути по-прежнему считаем равным сумме стоимостей входящих в него ребер. 
Для заданных вершин $s$ и $t$ требуется найти путь, их соединяющий, максимального веса (задача 1-1). 
Предполагается, что в сети нет контуров положительного веса. Естественно, все алгоритмы вначале считают «расстояния», а потом обратным ходом находят требуемый путь. 
Два метода решения.

**Первый.**
Поменять у весов всех ребер знак на противоположный и решать задачу на минимум. Полученный путь и будет ответом.

**Второй.**
В алгоритме Форда, Беллмана поменять знак $<$ на $>$.

### Замечание.

Для сетей с неотрицательными весами задача сводится к бесконтурным сетям, то есть, применим Безымянный алгоритм. 
Обе эти задачи (min и max) имеют применение в сетевом планировании.

## Сетевое планирование(Метод критического пути).

Предположим, что нужно реализовать некий проект $W$.
Проект $W$ разбивается на несколько отдельных видов работ $w_1,w_2,...,w_n$.
Для каждой работы $w_i$ известно (или может быть достаточно точно оценено) время ее выполнения $t(w_i)$.
Для каждой работы $w_i$ известен список работ, после полного завершения которых, работа $w_i$ может начинать выполняться. Обозначим такой список через $ПРЕДШ(w_i)$.
Спрашивается: когда можно ожидать время завершения всего проекта? Построим сетевую модель выполнения проекта

$G = (V,E,c)\\
V = W \cup \{v_0\} \cup \{v_{n+1}\} здесь\ v_0 - начало, v_{n+1} - конец\ всего\ проекта.\\
E = \{(v,w): v\in ПРЕДШ(w)\}\cup \\ \cup \ \{(v_0,w): ПРЕДШ(w) = \empty\} \cup \{(w,v_{n+1}): w \in \cup \ ПРЕДШ(v)\}.\\
\begin{cases}c(v,w) = t(v).\\ c(v_0,w) = 0. \end{cases}$
Так построенную модель называют сетевым проектом (модель вершина (узел) – работа)

**Пример.**
Проект Стройка.

---

$$\begin{array}{|c|c|c|c|}\hline$
$\text{N} & \text{Работа} & \text{t} &\text{ПРЕДШ} \\\hline$
$1 &Фундамент &4 &\empty \\\hline$
$2 &Коробка &8 &1 \\\hline$
$2 &Электропроводка &2 &2 \\\hline$
$2 &Сантехмонтаж &3 &2 \\\hline$
$2 &Кровля &4 &2 \\\hline$
$2 &Отделка &5 &3,4 \\\hline$
$2 &Благоустройсвто &2 &5 \\\hline$
$\end{array}$$

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%205.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%205.png)

Сетевой график любого проекта - бесконтурный граф.

### Основные характеристики.

Наиболее ранний возможный срок начала ($РНАЧ$) работы. 
Наиболее ранний возможный срок выполнения ($РВЫП$) работы. 
$РНАЧ$ определяется как срок, когда все предшествующие работы сделаны. 
То есть, 
$РНАЧ (w) = max\{РВЫП(v): v \in ПРЕДШ(w)\}$ 
$РВЫП(w) = РНАЧ(w) + t(w)$
Иначе говоря, алгоритм таков. 
Последовательно вычислять максимальное «расстояние» от вершины $v_0$ до вершины $v_i,$ двигаясь по номерам вершин. 
Время завершения проекта – длина максимального пути от $v_0$ до $v_{n+1}$. Обозначим этот срок $Т$. 
Наиболее поздний допустимый срок начала (выполнения) $ПНАЧ$ работы – максимальное время, не увеличивающее срок $Т$ выполнения всего проекта.

В записи алгоритма, будем считать, что веса приписаны вершинам сети.

### Алгоритм расчета характеристик сетевого графика.

Вход: Бесконтурная, топологически отсортированная сеть $G=(V,E,c)$ где веса приписаны к вершинам.
Выход: массивы $РНАЧ$, $РВЫП$.

### Расчет РНАЧ и РВЫП.

```pascal
1. begin
2. for i = 0 to n + 1  do
3.   begin РНАЧ[i] = 0, РВЫП[i] = 0 
4.   end
5. for i = 1 to n + 1 do 
6.   begin 
7.     for w ∈ ПРЕДШ[i]  do  
8.       if РНАЧ[i] < РВЫП[w] then РНАЧ[i] = РВЫП[w]  
9.     РВЫП[i] = РНАЧ[i] + t(i) 
10    end
11. end
```

```python
for i in range(n + 2):
    ebeg[i] = efin[i] = 0
for i in range(1, n + 2):
    for w in prev(i):
        ebeg[i] = max(efin[w], ebeg[i])
    efin[i] = ebeg[i] + time[i]
```

### Расчет ПВЫП и ПНАЧ.

Считаем обратным ходом, начиная с вершины $v_{n+1}$.

```pascal
1. begin 
2. for i = 0 to n + 1 do 
3. begin  ПВЫП[i] = T
4. end 
5. for i = n + 1 downto 1 do
6.   begin 
7.     ПНАЧ[i] = ПВЫП[i] – t(i) 
8.       for w ∈ ∪{ПРЕДШ[k] : k ≥ i} do 
9.         ПВЫП[w] = min{ ПНАЧ [k]: k ≥ i} 
10.   end 
11. end
```

Вводится много характеристик резерва времени при выполнении работы, разберем только один, часто называемый независимый резерв времени.
$РЗРВ[v] = ПНАЧ[v] – РНАЧ[v]$.

**Сведем все результаты в одну таблицу, в которой отражен пример.**

Работы 0,1,2,4,6,8 имеют нулевой резерв времени. Это означает, что задержка в выполнении любой работы из этого списка, автоматически приводит к увеличению срока исполнения проекта. Через каждую работу с нулевым резервом проходит некоторый максимальный путь. Именно поэтому весь метод называют методом критического пути.

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%206.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%206.png)

# Лекция 8.

## Maх-min расстояния и пути между всеми парами вершин.

Пусть $G = (V, E, c)$ - сеть и $p$-некоторый путь от $v_0$ до $v_k$.
Положим $||p|| = min\{c(e): e\in p\}$.
Требуется от заданной до заданной вершины найти путь максимального веса.

**Примеры.**

ГЭС (Нурек и Саяно-Шушенск), космодром на мысе Канаверал. 
Общее для всех примеров 
Тяжелый неделимый груз требуется перевезти из пункта $А$ в пункт $В$ по самой надежной дороге. 
На входе имеется карта дорог и отмечены пункты $А$ и $В$. 
Решение. Строим сеть, все перекрестки и пункты $А$ и $В$ объявляем вершинами. Если есть дорога их соединяющая, то объявляем соответствующее ребро. Вес этого ребра положим равным минимуму из грузоподъемности самого хилого моста на этой дороге, либо грузоподъемности дороги. 
Тогда получаем задачу о max-min расстоянии от вершины, соответствующей пункту $А$ до вершины, соответствующей пункту $В$.
Вес несуществующего ребра положим равным $- \infty$.
Метод решения: модификация алгоритма Дейкстры (вычисления расстояний от фиксированной вершины до всех остальных)

### Алгоритм одной фразой.

Последовательно вычислять max-min – расстояния до очередной, самой дальней от $s$ вершины.

**Реализация алгоритма.**
Вход: сеть $G = (V, E, c)$, заданная матрицей весов, выделенная вершина $s$. 
Выход: массивы $Dm$ и $ПРЕД$, где 
$Dm[v] = max\{min\{c(e): e \in p, где\ р\ –\ путь\ от\ s\ до\ v\}\}$ 
$ПРЕД[v]$ – предпоследняя вершина в некотором пути максимального веса.
Сложность: $O(n^2)$.

```pascal
1. begin
2. Dm[s] = + ∞, ПРЕД[s] = 0, F = V\{s} 
3. for v ∈ F do 
4.   begin Dm[v] = c(s,v), ПРЕД[v] = s
5.   end 
6. for k = 1 to n - 1 do 
7.   begin w = max(F), F = F \ {w} 
8.     for v ∈ F do 
9.       if min{Dm[v],c(w,v)} > D[v] then
10.        begin Dm[v] = min{Dm[w],c(w,v)}, ПРЕД[v] = w 
11.        end
12.   end
13. end
```

Доказательство корректности такой модификации, делается точно также, как и в алгоритме Дейкстры.

**Теорема.**
Вычисление max-min расстояний имеет сложность $О(n^2)$.

## Пути между всеми парами вершин.

Пусть $G = (V, E, c)$ – сеть. Требуется для каждой пары вершин $v$ и $w$ выдать кратчайший путь от $v$ до $w$, где вес пути равен сумме весов входящих в него ребер. 
Считаем, что в сети нет контуров отрицательной длины и все вершины пронумерованы натуральными числами от 1 до $n$. 

### Первый метод решения.

От каждой вершины запустить алгоритм Форда, Беллмана. Тогда получим алгоритм сложности $O(n^4)$.

Есть алгоритм на порядок более быстрый, чем алгоритм Форда, Беллмана. Введем обозначение $d(k, i, j)$ – длина кратчайшего пути от $i$ до $j$, среди всех путей, все промежуточные вершины которых, имеют номер не более $k$.

### Алгоритм Флойда одной фразой.

Последовательно для всех $k, i, j$ вычислять $d(k, i, j)$, используя формулы $\begin{cases}
d(0, i, j) = c( i, j) \\ d(k+1, i, j) = min\{d(k, i, j), d(k, i,k+1) + d(k+1, j)\} \end{cases}$

Справедливы неравенства $d(0,i,j) ≥ d(1,i,j) ≥ ... ≥ d(n,i,j)$ Ответом к задаче является $d(n,i,j)$ поскольку в графе нет контуров отрицательной длины. 
Реализовать все это можно (как и в алгоритме Форда, Беллмана), не в трехмерной матрице, а в двумерной. 
Обозначим эту двумерную матрицу $D$. Оказывается, при каждом входе в цикл при заданном $k$, выполняются неравенства $D[i, j] ≤ d(k, i, j)$ и эти же неравенства сохраняются при выходе из этого цикла. 
То есть, в отличие от алгоритма Форда, Беллмана, $D$ является двумерным, а не одномерным массивом. Аналогичная ситуация с массивом (матрицей) $ПРЕД$.

**Реализация алгоритма.**
Вход: сеть $G = (V, E, c)$, заданная матрицей весов $А$.
Выход: матрицы $D$ и $ПРЕД$, где $D[i,j]$ – длина кратчайшего $(i,j)$-пути, $ПРЕД[i,j]$ – предпоследняя вершина в кратчайшем $(i,j)$ – пути.

```pascal
1. begin
2. for i = 1 to n do
3.   for j = 1 to n do 
4.     begin D[i, j] = A[i, j], ПРЕД[i, j] = i 
5.     end
6. for k = 1 to n do 
7.   for i = 1 to n do 
8.     for j = 1 to n do 
9.       if D[i, j] > D[i, k] + D[k, j] then
10.        begin D[i, j] = D[i, k] + D[k, j], ПРЕД[i, j] = ПРЕД[k, j] 
11.        end
12. end
```

```python
for i in range(1, n + 1):
    for j in range(1, n + 1):
        D[i][j] = A[i][j]
        prev[i][j] = i
for k in range(1, n + 1):
    for i in range(1, n + 1):
        for j in range(1, n + 1):
            if D[i][j] > D[i][k] + D[k][j]:
                D[i][j] = D[i][k] + D[k][j]
                prev[i][j] = prev[k][j]
```

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%207.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%207.png)

### Резюме.

Все задачи, можно условно обозначить так. ( * - обозначены задачи, рассмотренные в лекциях) 
1*. Min ∑ вес пути это сумма весов, входящих в него ребер и ищется	кратчайший путь*. 
2.* Max ∑ 
3*. Max ∏ 
4. Min ∏ 
5. Max min 
6. Min max 
7. Max max Min min 
Отмечу задачу 3. Max ∏ . Можно решать, сводя через – $\log{c(v,w)}$ к стандартной на Min ∑. Но это плохо, лучше прямо в алгоритме Форда, Беллмана поменять знак суммы на знак произведения и знак > поменять на < . А в алгоритме Дейкстры искать не minF а maxF.
Ну и надо понять чему равен вес несуществующего ребра.

# Лекция 9.

## Потоки в сетях.

Пусть $G = (V,E,c)$ – сеть с выделенными вершинами $s$ и $t$.
$f(v-), f(v+)$ – втекающий поток и вытекающий, где
$f(v-) = \sum \{f(w,v): по\ всем\ w\} \\ 
f (v+) = \sum \{f(v,w): по\ всем\ w\}$
Потоком $f$ в сети $G$ называется функция на ребрах, $f : E \to R$, удовлетворяющая двум условиям 
1. $\forall e: 0 ≤ f(e) ≤ c(e)$, ограничение по пропускной способности ребра

2. $\forall v, v≠s, t : f(v-) = f(v+)$, сохранение потока в вершинах,  $v ≠ s, t$. 
Положим $║f║= f(s+)$ – величина потока $f$. Поток наибольшей величины называется максимальным.

### Задача.

В заданной сети найти максимальный поток.

---

$c=1$ на каждом ребре.
Поток f на ребрах $(s,1), (1,2), (2,t)$ равен $1$, а на ребрах $(s,2)$ и $(1,t)$ равен $0$. 

$||f|| = 1.$

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%208.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%208.png)

Понятно, что это не максимальный поток в этой сети.

$c=1$ на каждом ребре
$f(1,2)=f(2,3)=f(3,1)=1$
$f(s,1)=f(1,t)=0$

$||f||=0.$

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%209.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%209.png)

Это пример ненулевого потока величины 0.

Поток можно представлять как жидкость, которая течет по трубам. 
У каждой трубы есть диаметр, который ограничивает величину потока по ней. Т.о, получаем первое условие в определении потока. 
Второе означает, что потерь в узлах не происходит. 
А величина потока означает лишь сколько жидкости мы пропускаем по всей системе трубопроводов. 
Можно поток представлять как транспорт, проезжающий по улицам города. 
Каждая улица имеет пропускную способность, т.е., сколько машин может проехать по данной улице в единицу времени (ограничение по пропускной способности), и машины не бьются на перекрестках (сохранение потока в вершинах). 
А здесь приведу не очевидный пример задачи, которая сводится к задаче о максимальном потоке.

### Задача планирования производства.

Предприятию, располагающему $K$ однотипными станками, требуется изготовить партию из $N$ изделий в заданный срок $M$ дней.

Пусть все изделия пронумерованы натуральными числами
$i = 1, 2,…,N$, а все дни  $j = 1,2,…,M$. 
Для каждого изделия $i$ заданы 
$T_i$ – день, когда можно начинать его изготавливать;
$A_i$ – количество дней на его изготовление;
$D_i$ – утро того дня, к которому это изделие должно быть готово. Предполагается, что $T_i + A_i ≤ D_i.$
Каждое изделие может изготавливаться на любом станке, в процессе его изготовления могут быть перерывы, то есть, оно еще не готово, но в этот день оно не изготавливается на каком-либо станке.
Будем считать, что если какое-то изделие изготавливается на каком-то станке, то в это день станок полностью загружен именно этим изделием. Спрашивается: «Может ли предприятие изготовить все изделия в заданный срок $M$?». 
Если «да», то каков план изготовления изделий? 
Сведем эту задачу к задаче о максимальном потоке.

**Построим сетевую модель.**

$G = (V,E.c)$, где 
Множество вершин
$V = \{s\} \cup I \cup J \cup {t}$, здесь $s$ и $t$ – источник и сток сети соответственно, 
$I$ – множество изделий, $J$ – множество всех дней. 
Множество ребер
$E = \{(s,i): i \in I\} \cup \{(i,j): Ti \leq i , j \leq Di \} ∪ \{(j,t): j \cup J\},$ 
т.е., вершину $s$ соединяем со всеми изделиями; 
каждое изделие соединяем с теми днями, когда оно может изготовляться; все дни соединяем с вершиной $t$. 
Функция пропускных способностей определяется следующим образом. Положим $c(s,i) = A_i$ , т.е., пропускная способность ребра, ведущего от источника к изделию, равна количеству дней для его изготовления;
$c(i,j) = 1$, каждый день используется только один станок для изготовления каждого изделия;
$c(j,t) = K$, так как предприятие располагает $K$ одинаковыми станками.
Получим сеть

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2010.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2010.png)

### Теорема.

План реализуем тогда и только тогда, когда величина максимального потока, в так построенной сети, равна $\sum \{А_i : i = 1, 2,..., N\}$

Докажем только ½ теоремы, а именно, содержательную часть. 
Пусть $f$ - максимальный поток в сети $G$ и $||f||=\sum\{А_i:i=1,2,..., N\}$. 
Так как, на каждом ребре, исходящем из $s, f(s,i) ≤ c(s,i) = А_i$ ., то на всех этих ребрах справедливо равенство $f(s,i) = А_i$ , а поскольку в каждое изделие входит только одно ребро, получаем, что $f(i-) = А_i$ , а значит и $f(i+) = А_i$ . 
То есть количество ребер, исходящих из и $i$ на которых $f(i,v) = 1$ тоже равно $А_i$. Поскольку для всех $j$ величина потока ограничена сверху числом $K$ получаем, что не более $K$ единичек втекают в вершину  $j$. Остается оформить план производства изделий. Изделие с номером $i$ делаем в тот день, когда $f(i,j) = 1$.
Условия $f(s,i) = А_i$ и $f(j-) = f(j+) ≤ K$ , гарантируют, что план производства будет выполнен с соблюдением всех ограничений.

### Эта задача известна в шутливой форме.

Требуется пожарить 3 бифштекса, каждый с двух сторон. Причем каждая сторона жарится ровно 1 минуту. Одновременно в сковороде помещаются 2 бифштекса. Спрашивается, можно ли пожарить бифштексы за 3 минуты?

Да можно. Сначала жарим 2 бифштекса с одной стороны, затем первый переворачиваем, а второй убираем со сковороды и заменяем его на третий. Во вторую минуту жарим эти бифштексы, затем убираем первый (он пожарен), в последнюю минуту переворачиваем третий и возвращаем второй. Задача решена. Как это решение выглядит на языке теории графов? 
$K = 2$, (станки, это и есть одна сторона сковороды); 
$N = 3$, (бифштексы, это и есть изделия);
$M = 3$, (минуты, это и есть дни);
$T_i = 1$, (любой бифштекс можно начинать жарить в первый день);
$А_i = 2$, (каждый бифштекс жарится 2 минуты);
$D_i = 3$, (за 3 минуты надо все бифштексы пожарить).
Сеть строится очевидным образом.

### Теорема существования.

В каждой сети существует максимальный поток.

**Доказательство.**
Пусть $G = (V,E.c)$ – заданная сеть. Занумеруем все ребра сети произвольным образом: $(e_1 , e_2,..., e_m)$. Пусть $f$ какой-то поток в $G$. Поток $f$ определяет некоторую точку в Евклидовом m-мерном пространстве $E^m.$
Обозначим это множество через $F$.
Итак $F = \{ f = (f(e_1 ),..., f(e_m)) : f –\ поток\ в\ G \}$. 
Покажем, что $F$ – компакт. Компактность в Евклидовом пространстве означает, что это множество ограничено и замкнуто. 
Ограниченность множества $F$ следует из того, что для каждого потока $f$ выполняются неравенства $0 ≤ f(e) ≤ c(e)$, это означает, что
$F \subset П\{ [0,c(e_i)]: i = 1,2,..., m\}$ , то есть множество $F$ ограничено по каждой координате. 

**Докажем замкнутость множества $F$.**
Пусть $g = (g_1,.., g_m)$ – произвольная предельная точка множества $F$. 
Докажем, что $g \in F$, то есть, точка $g$ является некоторым потоком в сети $G.$
Так как $g$ – предельная точка, то существует последовательность элементов множества $F \{f_k\}$ сходящаяся к $g$ в пространстве $E^m.$

Отметим, что сходимость в этом пространстве означает покоординатную сходимость, т.е., для любой $i$-координаты, последовательность ${f_{k_i}}$ сходится к $g_i$ при $k$ стремящимся к бесконечности. 
Но для функций $f_k$ выполняются неравенства $0 ≤ f_k(e_i )≤с(e_i)$, а в неравенствах можно переходить к пределу, значит $0 ≤ g_i ≤ с(e_i)$, что доказывает выполнение первого условия потока (ограничение по пропускной способности ребра).

**Докажем второе условие (сохранение потока в вершинах).**
Пусть $J-$, $J+$ обозначают все индексы ребер, входящих в вершину и выходящих из произвольной вершины $v, v≠s,t$.
Но для значений функций $f_{k_i}$ справедливы равенства
$f_{k_i}(v-)=f_{k_i}(v+)$, значит эти равенства справедливы и для пределов, поскольку предел суммы (а выражение слева представляет сумму по множеству $J-$, а правая – по $J+$), отсюда получаем равенство $g_i(v-) = g_i(v+)$ , то есть для точки $g$ выполняются оба условия потока. Значит $g \in F.$
Итак $F$  – компакт. А по теореме Вейерштрасса всякая непрерывная функция имеет максимум.
Рассмотрим функцию $P(f) = ║f║$, функция $Р$  непрерывна как линейная функция. Значит $Р$ имеет максимум. Точка максимума и является максимальным потоком. $\square$

# Лекция 10.

## Построение максимального потока.

Разрезом в сети $G$ называется пара множеств вершин $(S,T)$ такая, что
a) $s \in S, t \in T$
b) $S \cup T = V$
c) $S \cap T = \empty$ 
Пусть $(S, T)$ некоторый разрез, положим
$E(S \to T)  = \{e=vw: v \in T\},\\
E(T \to S) = \{e=vw: v \in T, w \in S\}$

**Пример.** ниже сеть, в которой $c(e)=1$ для $\forall e \in E$ и $f$ поток, со значениями, изображенными на картинке.

---

$S=\{s,4\}, T=\{1,2,3,t\}$
$E(S\to T)=\{s,1;s,2;4,t\}$
$E(T\to S)=\{1,4\}$

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2011.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2011.png)

Пусть $f(S \to T) = \sum \{f(e):e \in E(S \to T)\}$, аналогично $f(T \to S)$
Тогда, для этого разреза справедливы
$f(S\to T)=1,5; f(T\to S)=0,5.$

### Лемма 1.

Для любого потока $f$ и любого разреза $(S,T)$ справедливо равенство
$||f|| = f(S\to T) - f(T\to S)$.

Для произвольной вершины $v \in S$ верны равенства
$f(v+) - f(v-)=0$, если $v \neq s$, то $||f|| = f(s+)$.
Просуммируем по всем $v \in S$, получим $||f||=\sum (f(v+)-f(v-)).$
Пусть $e=v$, $w \in E$ и обе вершины входят в $S$. Тогда $f(v,w)$ фигурирует в сумме $f(v+)$ как часть потока, входящего из $v$, и в $f(w-)$ как часть входящего в $w$ потока. Тогда в правой части этого равенства все такие слагаемые взаимно уничтожаются, так как входят в сумму с противоположными знаками.
Оставшиеся слагаемые и дают требуемое. $\square$

### Следствие 1.

Для любого потока $f$ справедливо равенство $||f||=f(v-)$.

Достаточно рассмотреть такой разрез $T=V \setminus \{t\}, S=V \setminus T$.
Для такого разреза $f(S\to T)=f(v-$), и $f(T\to S)=0$. Теперь достаточно сослаться на лемму 1. 

**Определение.**
Пусть $(S,T)$ - разрез, положим $c(S,T)=\sum \{c(e):e \in E(S \to T)\}$.
**Пропускная способность разреза** - число $c(S,T)$.

**Пример.**
Для разреза, в котором 
$S=\{s,4\},T=\{1,2,3,t\}$ получается $c(S,T)=3$.

Для разреза, в котором
$S=\{s,1,2,3\},T=\{4,t\}$ получается $c(S,T)=2$.

---

### Следствие 2.

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2012.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2012.png)

$c=1$

Для любого потока $f$ и любого разреза $(S,T)$ справедливы неравенства $||f|| ≤ f(S\to T) ≤ c(S,T)$.
**Минимальный разрез** - разрез имеющий минимальную пропускную способность среди всех разрезов.

### Следствие 3.

Если для некоторого потока $f^*$ и некоторого разреза $(S^*, T^*)$ выполняется равенство $||f^*||=c(S^*,T^*)$, то поток $f^*$ - максимальный, а разрез $(S^*,T^*)$ - минимальный.

**Доказательство.**
Пусть $f$ - максимальный поток, а он существует по теореме существования, а $(S,T)$ - минимальный разрез, существование которого очевидно.
Тогда по следствию 2 и выбору $f$ и $(S,T)$ выполнятся неравенства 
$||f^*|| ≤ ||f|| ≤ c(S,T) ≤ c(S^*, T^*)$, поскольку крайние члены в этой цепочке совпадают, то неравенства превращаются в равенства. $\square$

**Определение.**
Введем понятие цепи в ориентированном графе, то есть, мы не смотрим на ориентацию ребер. Если ориентация ребра совпадает с ориентацией цепи, то говорим, что ребро в цепи прямое, в противном случае обратное. 
Пусть $р$ некоторая $(s,t)$-цепь, то есть р имеет вид
$s=v_0, e_0, v_1,…,v_k=t$, положим $\delta(e)=c(e) – f(e)$, если $е$ прямое в цепи $р$ и $\delta(e)= f(e)$, если $е$ – обратное. 
Пусть $\delta(p) = min\{\delta(e): e \in p \}$.

**Определение.**
$(s,t)$-цепь р называется $f$-дополняющей, если $\delta(p) > 0$.

**Пример.**

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2013.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2013.png)

Пусть $c = 1$ на каждом ребре.
Поток $f$ изображен на картинке, $||f|| = 1$.
Пусть $(s,t)$-цепь $р$ такая
$р = s, (s,2), 2, (1,2), 1, (1,t), t$.
В этой цепи ребра $(s,2)$ и $(1,t)$ – прямые, а ребро $(1,2)$ – обратное.
$\delta(p) = 1$, то есть, $р-f$-дополняющая $(s,t)$-цепь.

### Лемма 2.

Пусть $f$ - некоторый поток в сети $G$, а $р-f$ - дополняющая $(s,t)$-цепь. Тогда в сети $G$ существует поток $f^*$ такой, что $║f^*║ >║f║$.

**Доказательство.**
Поток $f^*$ построим конструктивно, а именно,
$$f^*(e)=\begin{cases}$
$f(e) + \delta(p),\ e \in p,\ е-\text{прямое в }p; \\$
$f(е) – \delta(p),\ e \in p,\ е-\text{обратное в }p; \\$
$f(e),\ e \text{ не входит в }p;$
$\end{cases}$$
Докажем, что $f^*$ - поток, то есть $f^*$ неотрицательна и выполняются условия 1) и 2) определения потока.

**Проверим первое условие (ограничение по пропускной способности).**
Пусть е прямое в р, используя определения $f^*$ и $\delta(p)$ получим

$0 ≤ f(e) < f^*(e)=f(e) + \delta(p) ≤ f(e) + \delta(e) =  f(e) + (c(e) – f(e)) = c(e)$, то есть, для прямых ребер цепи условие 1) выполняется. 
Пусть $е$ обратное в $р$. Так как $f^*(e)< f(e)$, то условие $f^*(e) ≤ c(e)$ выполняется. 
Проверим, что  $0 ≤ f^*(e)$. 
Действительно, $f^*(e) = f(e) –\delta(p) ≥ f(e) – \delta(e) = f(e) – f(e) = 0$.
Итак, функция $f^*$ удовлетворяет условию 1).

**Проверим второе условие (сохранение потока в вершинах).**
Пусть $v$ – вершина, отличная от $s$ и $t$, входит в цепь $р$. Пусть $х$ и $у$ соответственно те ребра, по которыми пришли и ушли из $v$. 
Возможны 4 случая.

**1 случай.** Пришли по прямому, ушли по прямому. 
В этом случае оба потока $f(v-)$ и $f(v+)$ увеличиваются на одно и то же число, так как, ребро х входит в $v$, а ребро у выходит из $v$. Отсюда получаем равенство для $f^*$, а именно, $f^*(v-) = f^*(v+)$.

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2014.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2014.png)

**2 случай.** Пришли по прямому, ушли по обратному. 
Тогда оба ребра х и у входят в вершину $v$. Следовательно они входят в сумму $f(v-)$. Но на ребре $х$ значение потока увеличивается на $\delta(p)$, а на ребре $у$, уменьшится на это же число. Значит $f^*(v-) = f(v-)$, а $f(v+)$ вообще не меняется, отсюда
$f^*(v-) = f^*(v+)$.

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2015.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2015.png)

Остальные два случая разбираются аналогично. Итак, $f^*$ - поток в $G$.

Осталось проверить, что величина потока $f^*$ больше чем у потока $f$. Более того, оказывается, что верно равенство $||f^*|| = ||f|| + \delta(p)$. Действительно, цепь $p$ начинается в $s$, но единственная вершина, из которой ребра только выходят, а на этом ребре добавится число $\delta(p)$. Значит, $f^*(s+) = f(s+) + \delta(p)$, то есть, 
$||f*|| = ||f|| + \delta(p)$. $\square$

**Пример.**

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2016.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2016.png)

Мы уже видели, что цепь $р=s, 2, 1, t$ является 
$f$-дополняющей и $\delta(p) = 1$.
Новый поток $f^*$ изображен ниже

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2017.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2017.png)

и для потока $f^*$ справедливо $||f^*|| = 2$.

# Лекция 11.

Построение потока $f^*$ будем описывать немного иначе.

Положим
$$sgn_p(e) = \begin{cases}$
$+1, e \in p, e\text{ прямое в } p\\$
$-1, e \in p, e\text{ обратное в } p\\$
$0, e \notin p$
$\end{cases}$$

В этих обозначениях поток $f^*$ описывается так: $f^*(e)=f(e) + sgn_p(e)\delta(p).$

### Теорема Форд, Фалкерсон. 1956.

Для потока $f$ в сети $G$ следующие условия эквивалентны.
1) Поток $f$ максимален.
2) Не существует $f-$дополняющей $(s, t)-$цепи.
3) Существует разрез $(S, T)$ такой, что $||f|| = c(S,T)$.

**Доказательство.**
Импликация 1) $\to$ 2) - это просто по другому сформулированная лемма 2.
Импликация 3) $\to$ 1) - доказана ранее (Следствие 3 из леммы 1).
Осталось доказать 2) $\to$ 3).

Пусть для потока $f$ не существует $f$-дополняющей $(s,t)-$цепи.
Построим требуемый разрез $(S, T)$.

В $S$ отнесем все вершины $v$ до которых существует цепь р такая, что $\delta(p) > 0$ и добавим в $S$ вершину $s$, а за $Т$ возьмем все остальное, т.е., $Т = V \setminus S$.

Пусть $е=vw$ ребро, которое идет из $S$ в $T$, т.е., $v \in S$, $w \in T$. Тогда, на этом ребре $е$, выполняется равенство $f(e) = c(e)$, так как в противном случае, цепь $р$, для которой $\delta(p)>0$ и которая заканчивается в v была бы продолжена до $w$. А это невозможно, по построению множеств $S$ и $T$.

Аналогично, если ребро $е=vw$ смотрит «навстречу», т.е., $v \in Т$, $w \in S$, получаем, что $f(e) = 0$, по тем же причинам.

Итак, если $е \in Е(S \to T)$, то $f(e) = c(e)$, (иначе говоря эти ребра забиты под завязку); если $е \in Е(T \to S)$, то $f(e) = 0$.

Но по лемме 1 выполняется равенство $║f║ = f(S \to T) – f(T \to S)$. Однако, для построенного разреза, $f(S \to T) = с(S,T)$, $f(T \to S) = 0$. Значит для этого разреза $║f║= с(S,T)$ отсюда следует, что $f$ - максимальный поток (а построенный разрез минимален). $\square$

### Следствие.

В произвольной сети величина максимального потока равна пропускной способности минимального разреза.

### Алгоритм Форд, Фалкерсон. 1956.

1. Нулевой поток объявить текущим потоком $f$.
2. Для текущего потока искать $f$-дополняющую $(s,t)$ - цепь $р$. 
3. Если такая цепь р построена, то увеличить текущий поток $f$ по формуле
$f(e) = f(e)+ sgn_p (e)* h(p)$ и на шаг 2. 
4. Иначе. СТОП. Текущий поток максимален.

Закончит ли алгоритм работу построением максимального потока? Оказывается ответ отрицателен. Соответствующий пример такой сети привели Форд и Фалкерсон. Оказывается можно так злоумышленно выбирать $f$-дополняющую $(s,t)$-цепь $р$, что процесс никогда не закончится, более того, величина каждого потока в течение всего времени работы алгоритма, будет меньше одной четверти величины максимального потока.

Более того, количество итераций увеличения потока, не является функцией от размерности задачи, то есть от $n$ и $m$.

**Пример.**

Цифры на ребрах указывают его пропускную способность.

Если на каждом нечетном шаге выбирать $f$-дополняющую $(s,t)-$цепь такую, что $s \to 1 \to 2 \to t$, а на четном
$s \to 2 ← 1 \to t$, то текущий поток увеличивается ровно на 1. Значит максимальный поток будет построен через $2М$ итераций, что не является функцией от $n$ и $m$.

Заметим, что если пропускные способности являются целыми числами, то каждый промежуточный и максимальный потоки, тоже являются целочисленными, поскольку $\delta(p)$ целое число. Следовательно, каждый раз поток возрастает как минимум на 1, и значит, максимальный поток точно будет построен после не более чем $\sum \{c(s,v): \forall v \}$ итераций.

Отсюда следует, что если все пропускные способности суть рациональные числа, то максимальный поток тоже будет построен, поскольку справедливо.

### Утверждение.

Если $f$ – поток, то $Аf$ тоже поток для любого $А: 0 \leq А \leq 1$.

### Теорема Эдмондс, Карп. 1972.

Если на каждой итерации алгоритма Форда, Фалкерсона выбирать кратчайшую по числу ребер $f$-дополняющую $(s,t)$-цепь $р$, то построение максимально потока требует не более чем $\frac{m(n+2)}{2}$ итераций. Без доказательства.

### Теорема.

Алгоритм Форда, Фалкерсона имеет сложность $O(m^2 n)$ или $O(n^5)$.
Следует из вышеизложенного.

Итак, для поиска $f$-дополняющей $(s,t)$-цепи $р$, есть только один метод, а именно, поиск в ширину; поиск в глубину не годится, так как он не обеспечивает минимальности количества ребер в найденном пути.

Будем считать, что перед входом в очередную итерацию увеличения текущего потока выполняются равенства $\delta(v) = +∞$ для всех $v \in V$.

Число $\delta(v)$ играет двойную роль, если $\delta(v) = +∞$, то это будет означать что вершина $v$ еще не помечена, а если $\delta(v)$ число, то это означает, что вершина $v$ помечена и до нее существует цепь $p$ из $s$ такая, что $\delta(p) = \delta(v)$.

Опишем правила Поиска. Их три. 
С чего начать (начало); 
Как двигаться (движение); 
Чем закончить (окончание).

**Начало.** 
Вершина $s$. Считаем, что $s$ помечена, правда положим $\delta(s) = +∞.$

**Движение.** 
Пусть $v$ помечена, а $w$  не помечена и вершины $v$ и $w$ соединены ребром. Надо различать и по какому именно ребру помечаем эту вершину $w$ 

- По прямому ребру. Помечаем $w$ из $v$, если $f(v,w) < c(v,w)$, присвоив $w$ метку $\delta(w)=min\{ \delta(v), c(v,w) – f(v,w) \}.$
- По обратному ребру. Если $f(w,v) > 0$, полагаем $\delta(w) = min\{ \delta(v), f(w,v) \}$.

Тот факт, что w помечена из $v$, полагаем, что  $ПРЕД[w] = v$, а с помощью какого именно ребра, то полагаем $СПСБ[w] = 1$, если по прямому ребру $v$,$w$, а если по обратному 
(т.е., $w,v$), то $СПСБ[w] = -1$.

**Окончание.** 
Как только вершина $t$ получит числовую метку, т.е., $\delta(t) < +∞$, что говорит о том , что $f$-дополняющая $(s,t)$-цепь $р$ найдена, она легко восстанавливается с помощью массива $ПРЕД$ и $\delta(p) = \delta(t)$. Либо ни одной новой вершины пометить нельзя, что означает, что 
$f$-дополняющей $(s,t)$-цепи не существует.

**Пример.**

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2018.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2018.png)

# Лекция 12.

## Некоторые другие задачи о потоках.

### Поток в сети со многими источниками и стоками.

Задана сеть $G = (V,E,c)$, в которой выделены два подмножества множества вершин:
$S = {s_1,...,s_k}$ – источники, т.е., вершины из которых ребра только выходят,
$Т = {t_1,...,t_l}$ – стоки, т.е., вершины в которые ребра только входят;
функция $с$ – неотрицательна.
Потоком в сети $G$ называется функция на ребрах удовлетворяющая условию ограничения по пропускной способности ребра и сохраняющая поток на всех вершинах кроме источников и стоков.
Величиной потока называется число $\sum \{f(s_i+): по\ всем\ i\}$.

**Задача.** 
В заданной сети со многими источниками и стоками найти максимальный поток.

**Метод.** 
Сведение к стандартной в подходяще построенной сети.

**Решение.**
Добавим две вершины - $s^*$ и $t^*$. $s^*$ соединяем с каждым источником, а каждый сток соединяем с $t^*$. Пропускные способности новых ребер положим бесконечности.

### Поток в сети с ограничениями на пропускную способность вершин и ребер.

Задана сеть с двумя функциями $G = (V,E,c,d)$; где 
$с$ – пропускная способность ребер,
$d$ – пропускная способность вершин.
Допустимым потоком в такой сети называется поток $f$ (т.е. выполняются условия 1) и 2) потока) и удовлетворяющая еще одному условию
3) Для любой вершины $v, v\neq s,t$; поток, проходящий через эту вершину, не превосходит $d(v)$, т.е., $f(v) \leq d(v)$, для $v=s,t:  f(v) = f(s+) = f(t-)$.

**Задача.** 
В заданной сети, с ограничениями на пропускные способности вершин и ребер, найти максимальный допустимый поток.

**Метод.** 
Сведение к стандартной в подходяще построенной сети.

**Решение.**
Каждую вершину $v$, кроме $s$ и $t$, разобьем на две $v-$ и $v+$. Будем считать, что ребра входящие в вершину v входят в $v-$ , а выходящие из  $v+$. Между
$v-$ и $v+$ проведем одно дополнительное ребро из $v-$ в $v+$ пропускной способностью  $d(v)$.
Изобразим сказанное на рисунке.

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2019.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2019.png)

Легко видеть, что максимальный поток в новой сети $G^0* = (V^*,E^*,c^*)$ однозначно определяет максимальный допустимый поток в исходной сети.

### Поток в сети с ограничениями снизу.

Задана сеть $G = (V,E,c,d)$ где
$с$ – пропускная способность ребер (ограничивающая поток сверху),
$d$ – ограничение снизу потока на каждом ребре.
Обе функции неотрицательны: $0 \leq d(e) \leq c(e)\ \forall e \in E$.

Поток $f$ называется допустимым, если на каждом ребре е выполняются условия
 $0 \leq d(e) \leq  f(e) \leq c(e)$.

**Задача.** 
В заданной сети, с ограничениями на пропускные способности сверху и снизу, найти допустимый поток (не обязательно максимальный).

**Метод.** 
Сведение к стандартной в подходяще построенной сети.

**Решение.**
Опишем построение новой сети $G^* = (V^*,E^*,c^*)$ .
(Заметим, что новая сеть будет мультисетью, т.е., между некоторыми вершинами имеется более одного ребра)

Положим

$V^*= V \cup \{s^*\} \cup \{t^*\}$ (т.е., добавляются новые источник и сток).

Каждое ребро $е = vw$ из $E$ такое, что $d(e) > 0$ порождает три ребра
$(v,t^*)$ – т.е., из вершины из которой исходит ребро $е$ проводится ребро в новый сток $t^*$;
$(s^*,w)$ – т.е., проводится ребро из нового источника $s^*$ в вершину в которую входит ребро $е$;
Старое ребро $е$  остается и добавляется еще одно ребро из старого стока в старый источник $(t,s)$.

Итак
$E^* = \{(v,t^*) , (s^*,w): vw \in E, d(e) > 0 \} \cup E \cup \{(t,s)\}$

Пропускные способности ребер определим следующим образом.
$c^*(v,w) = c(v,w) – d(v,w)$, для всех ребер из $V$, таких, что $d(v,w) > 0$;
$c^*(v,t^*) = c(w,s^*) = d(v,w)$, для всех ребер из $V$, таких, что $d(v,w) > 0$;
$c^*(t,s) = + ∞$.

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2020.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2020.png)

### Теорема.

Допустимый поток в сети $G$ существует, тогда и только тогда, когда 	величина максимального потока в сети $G^*$ равна $\sum\{d(v,w) : \forall vw \in Е \}$.

**Доказательство.**

Пусть $f^*$ максимальный поток в $G^*$ величина которого равна $\sum \{d(v,w)\}$.
Отметим, что все ребра, выходящие из $s^*$, и все ребра, входящие в $t^*$,   забиты полностью.
Для каждого ребра $vw$ из $G$ положим $f(v,w) = f^*(v,w) + d(v,w)$.
Покажем, что $f$ – допустимый поток в $G$. Проверим оба условия.
(Ограничение по пропускной способности). Пусть $е$ произвольно из $Е$.
Тогда
$f(v,w) = f^*(v,w) + d(v,w) ≤ c^*(v,w) + d(v,w) ≤ (c(v,w) – d(v.w)) + d(v,w) = c(v,w)$
и $f(v,w) ≥ d(v,w)$, так как,$f^*$ - поток в $G^*$.
2) (Сохранение потока в вершинах). Пусть  v произвольная вершина и $v\neq s,t$ .
Тогда для любого ребра исходящего из $v$ и ведущего в $w$, произошло просто переключение величины потока, с ребра $(w,t^*)$ на ребро $(v,w)$. Значит поток, выходящий из $v$ не меняется, аналогично с потоком , входящим в вершину $v$.
А поскольку $f^*$ - поток, то и $f$ – поток, причем допустимый. См. рисунок. $\square$

![%D0%9A%D0%BE%D0%BC%D0%B1%D0%B8%D0%BD%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20f4b3549e637a487ba892945f8d0960d2/Untitled%2021.png](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2021.png)

**Решение 2.**

**Алгоритм**

1. В исходной сети $G$ построить максимальный поток $f$.
2. Если величина потока $f$ меньше $k$, то ответ «Нет».
3. Иначе. Для каждого ребра e, положить $f^*(e) = (k / ║f║) * f(e)$.
4. Вывести $f$

Корректность приведенного алгоритма следует из справедливости следующего утверждения.

Утверждение. Если $f$ поток в произвольной сети $G$, то $\forall p \in (0, 1)$, функция $f^* = pf$, тоже поток в той же сети $G$, величина которого равна $p║f║$.

Справедливость этого утверждения легко проверяется. 

Однако этот метод имеет существенный недостаток. А именно, если веса всех ребер суть целые числа, то максимальный поток $f$ построенный алгоритмом Форда-Фалкерсона, также на каждом ребре представляет собой целое число, однако при переходе к потоку $f^*$ целочисленность может потеряться.

**Решение 3.**

**Метод**

В стандартном алгоритме Форда-Фалкерсона, отслеживать величину, на которую увеличивается текущий поток. Детали в приводимом ниже алгоритме.

**Алгоритм**

1.Начать с нулевого потока, т.е., положить $f(e) = 0$  для каждого ребра $е$

2. Искать $f$ – дополняющую $(s,t)$-цепь $p$.

3. Если такая цепь $p$ построена.

4. Если $h(p) + ║f║ < k$, то $f(e) := f (e) + sgnp(e)*h(p)$ и шаг 2. 

5. Иначе. $f(e) := f(e) + sgnp(e)(k –║f║)$.

6. СТОП. Вывести $f$. 

7. Иначе (3). Вывести ответ «Нет».

В комментариях нуждается только шаг 5. Действительно, перед той итерацией, когда величина нового пока превзойдет заданное число $k$, величина текущего потока строго меньше $k$, поэтому число $║f║ + h(p) < k$, в частности, $k - ║f║ > 0$, значит увеличивать текущий поток на это число можно. Далее, величина нового потока увеличится на число $k - ║f║$ и в результате станет в точности равна $k$.

# Лекция 1.

### Поток заданной величины

**Постановка задачи.** 

Для заданных сети $G = (V,E,c)$ и числа $k$ найти поток в сети $G$ величины $k$ .
Поскольку эта задача является промежуточной для более важной задачи, которую сформулируем позже, то здесь приведем три возможных решения поставленной задачи.

**Решение 1.** 

**Метод.** 

Сведение к стандартной в подходяще построенной сети.

Добавим в заданную сеть $G$ одну новую вершину $s^*$ и новое ребро $(s^*,s)$ пропускной способностью $k$. Новую сеть обозначим $G^*$.

**Алгоритм**

1.  В сети $G^*$ построить максимальный поток $f^*$.
2.  Если величина потока $f^*$ меньше $k$, то ответ «Нет»
3.    Иначе. Взять в качестве $f$ сужение $f^*$ на $G$.
/*  Т.е., игнорировать $f^*(s^*,s)$  */
4.  Вывести $f$.

# Лекция 2.

## Задача о потоке минимальной стоимости.

**Постановка задачи**

Заданы сеть $G = (V,E,c,r)$, число $k$.
Функция $c: E \to \mathbb{R}$ - как обычно, ограничения по пропускной способности ребер, а функция $r: E \to \mathbb{R}$ - стоимость прохождения единицы потока по ребру $e$. Обе функции неотрицательны. Кроме того, задано число $k$.
Требуется найти поток $f$ такой, что
1. $║f║ = k$.
2. Стоимость потока $r(f)$ минимальна среди всех потоков величины $k$.
Здесь $r(f) = \sum \{r(e)f(e): e \in E\}$
Величину $r(f)$ называют стоимостью потока $f$.

**Пример**

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2022.png)

Здесь функция $с = 1$ на каждом ребре, $r(s,2) = r(1,t) = 10$, на остальных
$r = 1, k = 1$

Легко видеть, что максимальный поток в этой сети равен 2, (одна единица течет поверху, и еще одна снизу, а поток на ребре (1,2) равен нулю), но нам нужен поток величины 1.
Пусть поток величины 1 проходит по верхним ребрам, а на остальных 0.
Тогда стоимость этого потока равна 11, конечно это не минимальный по стоимости поток.
Можно доказать, что поток $f$ такой, что $f(s,1) = f(1,2) = f(2,t)$ является решением задачи о потоке минимальной стоимости.
Стоимость этого потока равна 3, а величина 1.

### Транспортная задача

Ниже приведен другой пример задачи о потоке минимальной стоимости. Это знаменитая транспортная задача из линейного программирования.

Даны

- число $n, i = 1,2,…,n$ - поставщики продукции;
- число $m, j = 1,2,…,m$ - потребители продукции;
- числа $\alpha(i)$ - предложение $i$-го поставщика;
- числа $\beta(j)$ - спрос $j$-го потребителя;
- числа $c(i,j)$ - стоимость доставки одной единицы продукции от $i$-го поставщика $j$-му потребителю.

Задача сбалансирована: $\sum \{ \alpha(i): i = 1,…,n\} = \sum \{ \beta(j): j = 1,…,m\}$
Требуется развести всю продукцию от поставщиков к потребителям, с учетом спроса и предложения, затратив наименьшую сумму денежных единиц.

**Математическое решение**

Обозначим $x(i,j)$ - количество продукции поставляемого $i$-тым поставщиком $j$-му потребителю. Требуется найти $x(i,j)$ так, чтобы выполнялись условия

- $x(i,j) ≥ 0$
- $\forall i : \alpha(i) = \sum \{x(i,j): j = 1,…,m\}$ То есть, от каждого поставщика вывозится вся продукция.
- $\forall j : \beta(j) = \sum \{x(i,j): i = 1,…,n\}$ То есть, каждому потребителю привозится ровно столько продукции сколько ему требуется.
- $\sum \{c(i,j) x(i,j) : i = 1,2,   n; j = 1,2,…,m\} \to min.$

Отметим, что в последней строке сумма никуда не стремится, а просто это принятое обозначение, что соответствующая сумма принимает минимальное значение среди всех сумм, удовлетворяющих предыдущим условиям.
Для решения транспортной задачи имеются стандартные алгоритмы линейного программирования, здесь мы покажем, что эта задача является частным случаем задачи о потоке минимальной стоимости.

**Сетевая модель**

Построим сетевую модель.
Положим $G = (V,E,c^*,r)$, $k$ следующим образом.
$V = \{s\} \cup \{i: i=\overline{1,n}\} \cup \{j:j = \overline{1,m}\} \cup \{t\}.$
То есть множество вершин в этой сети образуют все поставщики, все потребители и две новые вершины источник и сток сети.

$E = \{(s,i): i = \overline{1,n}\} \cup \{(i,j): i =\overline{1,n}; j = \overline{1,m}\} \cup \{(j,t): j = \overline{1,m}\}.$
То есть ребра строятся так: от источника к каждому поставщику, от каждого поставщика к каждому потребителю и от каждого потребителя к стоку.

Определим пропускные способности ребер, мне придется здесь использовать обозначения $с^*$, чтобы не путать с постановкой транспортной задачи.
$с^*(s,i) = \alpha(i);\space c^*(j,t) = \beta(j);\space c^*(i,j) = + ∞$.

$r (s,i) = r(j,t) = 0;\space r(i,j) = c(i,j)$ (а здесь уже функция с из транспортной задачи).
$k = \sum \{\alpha(i): i = \overline{1,n}\}$, что тоже самое, что и $\sum\{\beta(j): j = \overline{1,m} \}$, поскольку задача сбалансирована (суммарный спрос равен суммарному предложению)
Ниже, на рисунке приведена сетевая модель транспортной задачи.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2023.png)

### Теорема о решении транспортной задачи

Решение задачи о потоке минимальной стоимости величины $k$ однозначно определяет решение транспортной задачи.

**Доказательство.**

Действительно. Пусть $f$ - поток величины $k$ минимальной стоимости.
Положим $x(i,j) = f(i,j)$. Тогда

Условие 1 (решения транспортной задачи). Выполняется так как значения потока на каждом ребре неотрицательно.

Условие 2. Выполняется, так как, величина потока равна $k$, то есть
$k = \sum\{\alpha(i): i = \overline{1,n}\}$
и, следовательно, на каждом ребре $(s,i)$ выполняется равенство $f(s,i) = \alpha(i)$.
Это означает, что втекающий поток в каждую вершину $i$ равен $\alpha(i)$, но тогда и вытекающий поток из вершины $i$ равен $\alpha(i)$, то есть справедливо равенство
$\alpha (i) = \sum \{f(i,j): j = \overline{1,m}\}$ иначе говоря, $\alpha (i) = \sum \{x(i,j): j = \overline{1,m}\}$
что и означает справедливость условия 2.

Справедливость условия 3 проверяется точно также.
Наконец, $r(f) = \sum \{r(e)f(e): e \in E\}$, с учетом определения функции стоимости имеем
$r(f) = \sum \{r(i,j)f(i,j): i = \overline{1,n}; j = \overline{1,m}\} = \sum \{c_{i,j},x_{i,j}: \overline{1,n}; j = \overline{1,m}\}$, что завершает доказательство.

### Прямой алгоритм решения задачи о потоке минимальной стоимости

В задаче о потоке минимальной стоимости два параметра: величина потока и его стоимость. Ниже приведем два алгоритма решения этой задачи. Прямой алгоритм, где сначала строится поток заданной величины, а затем минимизируется стоимость и обратный: сразу строится оптимальный по стоимости поток, а затем, сохраняя оптимальность по стоимости постепенно поток увеличивается до требуемой величины

**Прямой алгоритм**

Вначале введем некоторые новые понятия. Пусть $q$ некоторый цикл в сети $G$ и $f$ - поток в ней. Для любого ребра $e$ из $q$ положим

$$
h(e) = \begin{cases}
c(e) - f(e), \text{если ребро } e \text{ входит в } q \text{ как прямое;}\\
0, \text{не входит в } q\\
f(e), \text{если ребро } e \text{ входит в } q \text{ как обратное;}
 \end{cases}
$$

$h(q) = min \{h(e): e \in q\}$
 
**Определение.** Цикл $q$ называется $f$-корректирующим, если $h(q) > 0$.
Внимательный читатель конечно заметил, что это определение в точности повторяет определение $f$-дополняющей $(s,t)$-цепи, данное выше. Здесь мы только распространяем это определение на циклы.

Пусть $q$ некоторый цикл
Напомним, что 

$sqn_q(e)= \begin{cases}
+1, \text{ если ребро } e \text{ входит в } q \text{ как прямое;}\\
0, \text{ не входит в } q\\
- 1, \text{ если ребро } e \text{ входит в } q \text{ как обратное;} \end{cases}$

**Определение.** Положим $r(q) = \sum\{r(e)sgn_q(e): e \in q\}$, число $r(q)$ называется стоимостью цикла $q$.

### Лемма 2Н (новая)

Пусть $f$ – поток, $q$ - некоторый $f$-корректирующий цикл отрицательной стоимости,
$f^*$- новый поток, полученный из $f$ по формуле $f^*(e) = f(e) + sgn_q(e)h(q)$.

Тогда величины потоков $f$ и $f^*$совпадают. Cтоимость $f^*$ меньше стоимости потока $f$ .

**Доказательство**

То, что $f^*$ является потоком в сети $G$ проверяется точно так же как и в доказательстве леммы 2.
Покажем, что $f^*$ является потоком той же величины, но меньшей стоимости.

Вначале докажем равенство $║f^*║ = ║f║$.

Пусть вершина s не входит в цикл q . Тогда в вершине s ничего не происходит и, следовательно, $║f^*║ = f^*(s+) = f(s+) = ║f║$.
Пусть теперь вершина s входит в цикл $q$ . Но ребра из $s$ только выходят, значит пришли в $s$ по обратному ребру, а ушли по прямому ребру. Но тогда на обратном ребре поток уменьшится на число $h(q)$ , а на прямом увеличится на то же самоe число. Заметим, что так будет при каждом вхождении вершины $s$  в цикл $q$. Значит величина потока, вытекающего из вершины s не меняется. Отсюда получаем, что величины потоков$f^*$ и $f$ совпадают.

Найдем стоимость потока $f^*$.

$r(f^*) = \sum\{r(e)f^*(e):\forall e \in E\} = \sum\{r(e)(f(e) + sgn_q(e)h(q))\}
= \sum \{(r(e)f(e) + r(e)sgn_q(e)h(q))\} = \sum \{(r(e)f(e)\} + \sum \{r(e)sgn_q(e)h(q)\}
= r(f) + h(q)r(q) < r(f)$, так как $r(q) < 0$ (везде суммирование $\forall е \in Е$). $\square$

# Лекция 3.

Эта лемма фактически подсказывает алгоритм построения потока заданной величины, минимальной стоимости. Вначале надо построить поток заданной величины, затем каждый раз уменьшать стоимость, найдя корректирующий цикл отрицательной стоимости. А если корректирующих циклов отрицательной стоимости нет? Итак, необходима теорема, которая является полным аналогом теоремы Форда и Фалкерсона.

### Теорема

Поток $f$ величины $k$ является минимальным по стоимости среди всех потоков величины $k$, тогда и только тогда, когда в сети $G$ не существует $f$-корректирующего цикла отрицательной стоимости.

### Прямой алгоритм

1. Построить поток $f$ величины $k$.
2. Искать $f$-корректирующий цикл $q$ отрицательной стоимости.
3. Если такой цикл построен, то изменить поток $f$ по формуле, указанной в лемме 2 и шаг 2.
4. Иначе. СТОП. Поток $f$: минимальный по стоимости.

### Как искать f-корректирующий цикла отрицательной стоимости?

**Метод**

Поиск контура в подходяще построенной сети.

Годится небольшая модификация алгоритма Флойда, вычисления расстояний между всеми парами вершин.
Пусть $f$ - поток в сети $G$. Построим сеть вспомогательную сеть $G^* = (V^*, E^*, c^*)$. Она в большинстве книг называется остаточной сетью.
Положим
$V^* = V$;
В $E^*$ добавляем только те ребра, которые могут входить в исходной сети в $f$-корректирующий цикл. А именно, пусть ребро $e \in E$, тогда

- если $f(e) < c(e)$, то добавляем $e \in E^*$ как прямое и полагаем $c^*(e) = r(e)$;
- если $0 < f(e)$, то ребро $e$ добавляем в $E^*$ как обратное, т.е., у ребра $е$ меняем ориентацию, и полагаем $c^*(e) = -r(e)$;
- если выполняются оба условия, т.е, $0 < f(e) < c(e)$, то добавляем в $E^*$ оба ребра как прямое и обратное, со стоимостью как в случаях 1) и 2).

В сети $G^*$ Применим алгоритм Флойда вычисления расстояний между всеми парами вершин. Как только алгоритм Флойда найдет вершину $i$ такую, что расстояние от $i$ до $i$ меньше нуля, значит он нашел контур отрицательной длины в $G^*$, но по найденному контуру легко строится $f$-корректирующий цикл в исходной сети $G$.

**Алгоритм Флойда**

Вычисления расстояний между всеми парами вершин в сети.
Пусть в сети $G  = (V,E,c)$ все вершины пронумерованы натуральными числами от $1$ до $n$, причем вес несуществующего ребра равен $+∞$ .
Положим
$d_k(i ,j) = min\{\text{расстояний среди всех путей от i до j, содержащих не более k ребер}\}$.

**Алгоритм одной фразой**
Последовательно вычислять для всех $k, i, j \in 1,…,n$, используя формулы
$d_1(i ,j) = c(i,j)\\
d_{k+1} (i ,j) = min(d_k (i ,j), d_k (i ,k+1) + d_k (k+1,j)$.
Этот алгоритм работает, когда в сети нет контуров отрицательной длины.
А нам ведь нужен как раз такой контур?
Контур отрицательной длины существует тогда и только тогда, когда найдена вершина $i: d_k(i ,i) < 0$

**Пример**

Пусть пропускные способности и стоимости прохождения единицы потока для любого ребра равны $1$, кроме ребра $(1,2)$, где $с(1,2) =2$. Значения потока $f$ даны на Рис. 1 на остальных ребрах поток равен $0$. Число $k = 1$.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2024.png)

Величина этого потока равна $1$, а стоимость равна $3$. Рассмотрим цикл $q = 1,3,2,1$, иначе говоря, состоящий из ребер $(1,3);(2,3);(1,2)$.
Здесь ребро $(1,3)$ - прямое, а ребра $(2,3)$ и $(1,2)$ - обратные. Для этого цикла имеем
$h(q) = 1, r(q) = -1$.
Пусть поток $f^*$ получен из $f$ по формуле $f_1(e) = f(e) + sgn_q(e)h(q)$*.*
Ненулевые значения потока *$f$*  изображены на Рис. 2
Заметим, что величина потока $f^*$ по-прежнему равна $1$, а вот стоимость уменьшилась, и стала равной $2$. Это не случайный факт.

**Построим вспомогательный путь**

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2025.png)

Здесь 2 контура отрицательной стоимости, первый: $1-3-2-1$, 
второй: $2-4-3-2$.
Алгоритм Флойда, если все циклы в нем проводятся по порядку номеров, найдет контур $1-3-2-1$ и 
расстояние  $d_3 (1 ,1) < 0$.

---

По найденному контуру во вспомогательной сети легко строится нужный цикл в исходной сети.

**Оценка сложности**

Клейн (1967), $O(Mn^3)$, где $М$ – суммарная стоимость ребер.
Гольдберг, Тарьян (1987), $O(n^8logn)$, если на каждом шаге выбирается цикл со средней стоимостью.
Эмпирически ≈ $cn^{5,4}$

### Двойственный алгоритм

Итак, в задаче о потоке минимальной стоимости два параметра: величина потока и его стоимость. Прямой алгоритм действует так – сразу строится поток заданной величины, затем не меняя величины потока минимизируется его стоимость. Двойственный алгоритм действует наоборот – сразу строится оптимальный по стоимости поток, а затем он, не меняя оптимальности, доводится до заданной величины.

**Определение.**

Пусть $f$ - какой-либо поток в сети $G$ и величина его равна $k$. Назовем поток $f k$ -оптимальным, если он имеет наименьшую стоимость среди всех потоков величины $k$.

Например, поток тождественно равный 0 является 0-оптимальным.

### Теорема. Критерий k-оптимальности.

Поток $f$ величины $k$ является $k$ -оптимальным, тогда и только тогда, когда в сети $G$ не существует $f$-корректирующего цикла отрицательной стоимости.

Kлючевой для построения алгоритма является

### Теорема.

Пусть $f$ поток величины $k$ и $p-f$-дополняющая цепь минимальной стоимости среди всех $f$ -дополняющих $(s,t)$- цепей, поток $f^*$ получен из $f$ по формуле
$f^*(e) = f(e) + sgn_p(e)h(p)$.
Тогда $f^* - (k + h(p))$-оптимальный.

Без доказательства.

Напомню, что для величины потока f* выполняется равенство
$║f^*║ = ║f║ + h(p)$,

То есть, величина нового потока $f$ возрастает, не теряя оптимальности.
Это обстоятельство позволяет сформулировать следующий алгоритм

### Двойственный алгоритм решения задачи о минимальном потоке

Построить новую сеть, в которую добавлена одна вершина $s^*$ и одно новое ребро $(s^*,s)$, пропускной способностью $k$.

1. Нулевой поток объявить текущим.
2. Для текущего потока $f$ искать $f$-дополняющую $(s,t)$-цепь $p$ минимальной стоимости.
3. Если такая цепь $p$ построена, то увеличить $f$ по формулам
4. $f^*(e) = f(e) + sgn_p(e)h(p)$ $\forall e \in E$ и на шаг 2.
5. Иначе. СТОП.
6. Если $║f║ = k$, то поток $f$ является решением
7. Иначе. Решения не существует

### Как искать f-дополняющую (s,t)-цепь минимальной стоимости ?

**Метод**: алгоритм Форда, Беллмана в подходяще построенной сети.

Построим сеть

Пусть $f$ – текущий поток в сети $G$.
Построим вспомогательную сеть $G^* = (V^*, E^*, c^*)$.

Положим $V^* = V$.

В $E^*$ добавляем только те ребра, которые могут входить в исходной сети в $f$ –дополняющую $(s,t)$-цепь. А именно, пусть ребро $e \in E$, тогда

- если  $f(e) < c(e)$, то добавляем $e$ в $E^*$ как прямое и полагаем $c^*(e) = r(e)$;
- если $c(e) < f(e)$, то ребро e добавляем в $E^*$ как обратное, т.е., у ребра е меняем ориентацию, и полагаем $c^*(e) = - r(e)$;
- если выполняются оба условия, т.е, $0 < f(e) < c(e)$, то добавляем в $E^*$ оба ребра как прямое и обратное, со стоимостью как в случаях 1) и 2).

Внимательный читатель должен заметить, что строится та же самая сеть, что и в прямом алгоритме.

Но ведь алгоритм Форда, Беллмана работает только, если в сети нет контуров отрицательной длины! Здесь на выручку приходит сформулированная выше теорема, которую я даю без доказательства. Итак, контуров отрицательной длины нет, значит можно считать «расстояния» от вершины $s$ до всех остальных, правда нас интересует только «расстояние» до вершины $t$.

**Пример**
Возьмем известную вам транспортную задачу. Напомню формулировку.
Дано:

- 2 поставщика, предложение задается вектором (3,4);
- 2 потребителя, спрос задается вектором (2,5);
- Матрица стоимостей $$c(I,J) =  \begin{matrix} 1 &        2\\$
$3&10 \end{matrix}$$

Требуется развести весь товар с учетом спроса и предложения, минимизировав суммарную стоимость.

Для удобства будем нумеровать построенные потоки.
Применим двойственный алгоритм.
Итак $f_0$ на всех ребрах равен нулю. Он, конечно. $0$-оптимальный.

**Построим остаточную сеть.**
Прямо по построению, эта сеть не отличается от исходной. Ниже, на рисунке, изображена исходная сеть и числа на ребрах означают пропускные способности.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2026.png)

Внимательный читатель конечно заметил, что пропускные способности я определил немного не так как в лекции 2 а именно, я положил, что все ребра, исходящие от поставщика имеют пропускную способность не $+∞$, а предложение именно этого поставщика.
Поскольку, остаточная сеть для нулевого потока не отличается от исходной, то легко находится ПУТЬ от $s$ до $t$ имеющий наименьшую стоимость. Конечно, это путь, проходящий через вершины $s, 1, 3, t$.
Итак, поток на этих ребрах равен 2, на остальных – $0$. Обозначим этот поток через $f_1$

Нарисуем остаточную сеть для потока $f_1$ , числа возле ребер означают «длину» соответствующего ребра.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2027.png)

Кратчайший путь от $s$ до $t$ проходит через вершины $s, 1, 3, t$ («длина» его равна 2).
Новый поток $f_2$ описывается равенствами
$f_2 (s,1) = 3, f_2 (1,3) = f_2 (3,t) = 2, f_2(1,4) = f_2 (4,t) = 1$ на оставшихся ребрах – $0$

Остается построить потоки $f_3$  и $f_4$. 

Молва приписывает двойственный алгоритм Басакеру и Гоуэну, 1961 год. Имеющаяся на сегодня оценка сложности – экспонента от $n$.

# Лекция 4.

## Паросочетания.

**Определение**. 

Пусть $G = (V,E)$ произвольный граф. Паросочетанием в $G$ называется множество вершинно непересекающихся ребер. 

Или эквивалентное

Паросочетание - множество ребер, такое, что каждая вершина инцидентна не более чем одному ребру из этого множества.

### Задачи связанные с паросочетанием

1. Пусть имеется $n$ рабочих, каждый из которых может выполнить одну или несколько из видов работ. При этом каждый из видов работ должен быть выполнен одним рабочим и каждый рабочий выполняет только один из видов работ.
Требуется так распределить работы среди рабочих, чтобы наибольшее количество работ было выполнено.
2. Пусть в предыдущей задаче число рабочих равно числу видов работ.
Спрашивается, можно ли так распределить работы среди рабочих, чтобы были выполнены все виды работ?
3. Пусть сверх условий второй задачи для каждой пары рабочий – работа известна стоимость выполнения работы рабочим $x$ работы $y$.
Требуется так подобрать каждому рабочему определенный вид работы, чтобы суммарная стоимость выполнения всех работ была минимальна.

**Математическая модель**

Определим двудольный граф, в котором левая доля есть рабочие, а правая – работы. Множество ребер этого графа определим как то, что рабочий может выполнить эту работу.

Пусть $М$ – паросочетание в этом графе. Тогда каждое ребро можно интерпретировать как назначение рабочего на конкретный вид работы. Действительно, по определению паросочетания никакие два ребра не имеют общих вершин. Следовательно, на каждую работу назначается не более одного рабочего и каждый рабочий получает не более одной работы.

С этой точки зрения: 

Первая задача состоит в том, чтобы найти паросочетание с наибольшим количеством ребер (задача о наибольшем паросочетании),
вторая – выяснить существует ли паросочетание, состоящее из n ребер (задача о полном паросочетании),
третья – найти паросочетание, состоящее из n-ребер, с минимальным суммарным весом (задача о назначениях).

### Задача о максимальном паросочетании

**Определение.** 

Максимальное по включению паросочетание называется максимальным.

Или по другому, паросочетание является максимальным, если добавление любого нового ребра графа, приводит к появлению вершины степени 2.

**Пример.**

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2028.png)

Паросочетание, состоящее из одного ребра 2,3 является максимальным, но не наибольшим. (В паросочетании 1,2 и 3,4 ребер больше)

### Алгоритм построения максимального паросочетания

1. Сформировать из ребер графа $Е$, $ОЧЕРЕДЬ$. Положить $С = Ø$.
2. Пока ($ОЧЕРЕДЬ$  не пуста)
3. Начало цикла. Выбрать очередное ребро из структуры $ОЧЕРЕДЬ$, удалить его из 	$ОЧЕРЕДЬ$, если ни одна вершина не содержится в $С$, добавит в $С$ обе его вершины.
4. Конец цикла.
5. Конец алгоритма.

### Задача о наибольшем паросочетании

Паросочетание, имеющее наибольшее количество ребер называется наибольшим

Пусть $М$ – какое-либо паросочетание в графе. Для удобства, ребра, входящие в $М$ будем называть темными, а все остальные – светлыми.
Аналогично, вершины инцидентные темным ребрам назовем темными, а остальные – светлыми.

**Определение.**

Цепь $p = v_0 , e_0 , v_1 ,…, e_{k-1} , v_k$  называется $М$-чередующейся цепью, если
первая и последняя вершины – светлые, а все остальные – темные;
цвета ребер чередуются по правилу: светлое – темное.
Предполагается, что вершины цепи не повторяются.

**Пример.**

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2029.png)

Цепь 2, 3,1, 4 является $М$-чередующейся; Цепи 2,1,3 и 1,3 не являются $М$-чередующимися.

### Лемма (свойство М-чередующейся цепи)

Всякая $М$-чередующаяся цепь имеет нечетную длину (здесь под длиной цепи понимается количество ребер).

**Доказательство**

Достаточно заметить, что светлых ребер на единицу больше чем темных.

**Определение.**

Симметрической разностью двух множеств $А$ и $В$ называется их объединение без пересечения, то есть, $А \circ В = (А \cup В) \setminus(А \cap В)$ .

Несложно доказать, что $А \circ В = А\setminus В \cup В\setminus А.$

### Лемма 2 СПН (Супер-пупер новая).

Пусть $М$ паросочетание, а $р$ – $М$-чередующая цепь. Пусть, далее, $М^* = М \circ р$.
Тогда

1. $М^*$ - паросочетание.
2. $│М^*│ = │М│ + 1$.
Здесь $│М│$ обозначает мощность (то есть, количество элементов множества $М$)

**Доказательство**

Достаточно проверить, что степень каждой вершины относительно $М^*$ не больше 1. Действительно, пусть $v$ – произвольная вершина из $V$. Если $v$ не входит в цепь $р$, то с ребрами, ей инцидентными ничего не происходит, и, следовательно, степень относительно $М^*$ равна степени относительно $М$, то есть не превосходит 1.
Если $v$ входит в цепь $р$. Возможны два случая. Первый, вершина $v$ не крайняя в цепи. Тогда $v$ – темная, но теперь вершина $v$ становится инцидентной другому ребру из цепи $р$, значит степень вершины сохраняется. Если $v$ – крайняя в цепи $р$, то степень относительно $М$ равна нулю, а в $М^*$ она степень становится равной 1, так как, из светлой вершины она превращается в темную. $\square$

### Теорема (Берж, 1957 год)

Паросочетание $М$ является наибольшим в графе $G = (V,E)$ тогда и только тогда, когда не существует $М$-чередующейся цепи.

**Доказательство**

В доказательстве нуждается только достаточность, так как в другую сторону это перефразировка леммы 2.

Пусть для паросочетания $М$ не существует $М$-чередующейся цепи. Докажем, что $М$ является наибольшим паросочетанием.
Пусть $N$ – какое-то паросочетание. Покажем, что $│N│ \leq │М│$.
Рассмотрим граф $G^* = (V, M \circ N)$, то есть на том же множестве вершин $V$, а ребра из $M$ и $N$. Заметим, что в графе $G^*$ степень каждой вершины не превосходит двух. Тогда каждая компонента связности в графе $G^*$ может быть одного из следующих типов.
1. Изолированная вершина.
2. Цепь четной длины.
3. Цепь нечетной длины.
4. Цикл.

В случаях  1), 2) и 4) одинаковое число ребер из $М$ и $N$. А если компонента связности представляет собой цепь нечетной длины, то она либо $М$-чередующаяся, либо $N$-чередующаяся. Но, по условию, $М$-чередующихся цепей в графе нет, Следовательно могут быть только $N$-чередующиеся цепи. Но в каждой из этих цепей ребер из $М$ на единицу больше, чем из $N$. Отсюда получаем, что $│N│ \leq │М│$, то есть $М$ – наибольшее. $\square$

### Алгоритм построение наибольшего паросочетания (простой).

1. Пустое паросочетание $М$ объявить текущим.
2. Искать $М$-чередующуюся цепь $р$.
3. Если такая цепь р построена, то положить $М = М \circ р$, и на шаг 2.
4. Иначе. СТОП. Паросочетание $М$ –наибольшее.

Внимательный читатель конечно заметит, что это чуть подправленный алгоритм Форда и Фалкерсона. Корректность алгоритма следует из доказанной теоремы.
Каждый раз паросочетание увеличивается ровно на одно ребро, то сложность этого алгоритма должна быть $О(n^3)$ поскольку, сложность одной итерации будет $О(n^2)$ , если используется поиск в графе, будь то в ширину, или в глубину.

**Пример.**

Но не все так просто как кажется. Для иллюстрации приведем пример графа на четырех вершинах и четырех ребрах.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2030.png)

Текущее паросочетание $М$ состоит из одного ребра 2,3
Здесь это ребро отмечено прямой линией, а остальные – волнистой.

Пусть поиск $М$-чередующейся цепи начинается в вершине 1 и используется ПВГ. Тогда, если из 1 идти в 2, то следующий шаг будет только по темному ребру, придется идти в 3 и поиск на этом закончится, в то время как $М$-чередующаяся цепь, с началом в 1 существует (надо было из 1 идти в 3, затем в 2 и далее в 4). То есть, при реализации ПВГ придется учитывать нумерацию вершин, а это невозможно.

**Определение**.

Эдмондс выделил следующее понятие. Чередующийся цикл (цвета ребер меняются на каждом шаге) нечетной длины назовем цветком.
Первым предложил бороться с цветками Эдмондс (в 1965 году), он на каждом шаге, как только появится цветок, сжимал их в одну супервершину и продолжал поиск, а затем, на обратном ходу, только разжимал супервершины. В результате им был получен алгоритм сложности $О(n^4)$.
Только 10 лет спустя, советский математик Г.Н. Габов (выпускник матмеха ЛГУ, ныне живет в США, работает в Стэнфорде) разработал эффективную реализацию алгоритма Эдмондса, и получил алгоритм сложности $О(n^3)$.
Я не буду разбирать подробно алгоритм Эдмондса, с реализацией Габова, отмечу только, что цветков вообще не возникает, если в графе нет циклов нечетной длины. А это как раз характеристика двудольных графов. Именно поэтому все основные алгоритмы имеют место быть только для двудольных графов. Именно ими мы и займемся на следующей неделе.
Отмечу здесь только, что и лемма 2СПН, и теорема Бержа относятся к любым графам

# Лекция 5.

## Паросочетания в двудольных графах

**Определение**.

Граф $G = (V,E)$ называется двудольным, если множество вершин $V$ можно разбить на два подмножества $X$ и $Y$ так, что каждое ребро графа соединяет вершину $x \in X$ с вершиной $y \in Y$.
Двудольные графы будем записывать так $G = (X,Y,E)$

**Утверждение.**

Граф двудолен тогда и только тогда, когда в нем нет циклов нечетной длины.

Двудольный граф удобно задавать ¼ матрицы смежности размера $│X│× │Y│$.
Впрочем, верно и обратное: всякая матрица, каждый элемент которой либо 0, либо 1 однозначно определяет некоторый двудольный граф.

### Простой алгоритм построения наибольшего паросочетания

(модификация алгоритма Форда, Фалкерсона)

1. Пустое паросочетание объявить текущим.
2. Искать $М$-чередующуюся цепь $р$.
3. Если такая цепь $р$ построена, то увеличить паросочетание по формуле
$М = М \circ р$  и шаг 2
4. Иначе. СТОП. Текущее паросочетание $М$ наибольшее.

### Теорема.

Сложность простого алгоритма построения наибольшего паросочетания $O(p*n*q)$, где $p = │X│,\ q = │Y│,\ n = min(│X│,│Y│)$;
в частности, если $n = │X│ = │Y│$, то алгоритм имеет сложность $O(n^3)$.

**Доказательство**.
Поскольку алгоритм, начинает с пустого паросочетания и каждый раз текущее паросочетание прирастает ровно на одно ребро, то понадобится $n$ итераций возрастания паросочетания. Сложность одной итерации – это сложность поиска $М$-чередующейся цепи. Конечно, удобно здесь использовать ПВГ или ПВШ, которые имеют сложность $p*q$. $\square$

Напомню, что цепь $р:  v_0, e_1, v_1,…,v_k$ называется $М$-чередующейся, если она начинается и заканчивается в светлых вершинах $v_0$  и $v_k$, а цвета ребер чередуются по правилу светлое – темное.

В дальнейшем удобно считать, что $М$-чередующаяся цепь начинается в доле $X$, тогда она заканчивается в доле $Y$, и записывать $М$-чередующиеся цепи будем так: $x_0, e_1, y_1, …,e_{2k+1}, y_{2k+1}$.
Первое и все нечетные ребра – светлые, все четные – темные, цепь имеет нечетную длину.
Удобно изображать двудольный граф так, что доля $X$ слева, а доля $Y$ – справа, тогда все ребра $М$-чередующейся цепи, от вершин из $X$ в $Y$ – светлые, а от $Y$ к $X$ – темные.
Как искать $М$-чередующуюся цепь? Годится ПВГ или ПВШ.

Любой поиск в графе это три правила. Сформулирую их (они понадобятся позже).

1. Начало. Любая светлая вершина $x \in X$.
2. Движение. Пусть рассматривается ребро $vw$, причем вершина $v$ помечена (посещена), а вершина $w$ - нет. Все зависит от того, где лежит вершина $v$ и, следовательно, вершина $w$.
Тут два правила: от вершины $x\in X$ к $y\in Y$ и наоборот.
1.  Будем его называть слева-направо (то есть, от X к Y), по любому светлому ребру, то есть вершину $у\in Y$ можно пометить, если ребро $ху$ светлое.
2. Справа-налево. По темному ребру, то есть, из у можно пометить $х$ по ребру из $М$.
3. Окончание. Как только будет помечена свободная вершина $у\in Y$. В этом случае найдена $М$-чередующаяся цепь.
Либо, ни одной светлой вершины $у\in Y$ достичь не удалось и ни одной новой вершины пометить нельзя. Это означает, что $М$-чередующейся вершины с началом в корневой вершине поиска не существует.

ПРИМЕР

### Алгоритм Хопкрофта – Карпа.

**Определение.**

Цепь $р$ назовем $М$-цепью, если выполняются два условия:

1. начальная вершина $x_0$ – светлая
2. цвета ребер чередуются по правилу: светлое-темное и цепь имеет нечетную длину, то есть заканчивается в вершине $у\in Y$.

Отличие от $М$-чередующейся состоит в том, что цвет последней вершины может быть любым (светлым или темным). Понятно, что любая $М$-чередующаяся цепь является $М$-цепью, но не наоборот.

В приведенном выше примере цепи$х_3\leadsto у_2; х_4\leadsto у_2;   х_4\leadsto у_3$ являются $М$-цепями (но не $М$-чередующимися)

**Определение**. 

Максимальное по включению множество вершинно-непересекающихся $М$-чередующихся цепей назовем $М$-множеством.
Подчеркнем еще раз, что здесь идет речь о М-чередующихся цепях, а не об М-цепях.

Пусть $r$ – длина кратчайшей $М$-чередующейся цепи, через $G(M)$ обозначим граф, образованный всеми $М$-цепями длины не более $r$, то есть такой граф, через каждую вершину которого проходит некая $М$-цепь, длины не более $r$.
Если ни одной $М$-чередующейся цепи не существует, будем считать, что $G(M) = Ø$.

**Алгоритм Хопкрофта, Карпа (1973 г.)**
(Построение наибольшего паросочетания)

1. Пустое паросочетание $М$ объявить текущим.
2. Построить вспомогательный граф $G(M)$.
3. Если $G(M) ≠ Ø$, то
построить в $G(M)$ $М$-множество ${p_1, …, p_k}$;
положить $М1 = М \circ р_1; М2 = М1 \circ р_2 ,…, Мk = М(k-1) \circ р_k$ ; положить $М = Mk$ и вернуться на шаг 2.
4. Иначе. СТОП. $М$ – наибольшее.

**Пример.**

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2031.png)

Все ребра – светлые. Вершины доли $X$ изображены слева, а доли $Y$ – справа.
Итак, начинаем. Положим $М = Ø$. Поскольку каждое ребро является $М$-чередующейся цепью кратчайшей длины, то $G(M) = G$. Тогда $М$-множеством является, например, такое $\{p_1 = \{x_1,у_2\}, p_2 = \{x_4,y_3\} \}$ (читатель, конечно заметил, что мы действуем максимально злоумышленно). Легко видеть, что это действительно максимальное по включению множество вершинно-непересекающихся $М$-чередующих цепей.
Увеличим текущее паросочетание сразу вдоль этих двух цепей (рис 2).

Тогда $r = 3$. (Напомню, что $r$ обозначает длину кратчайшей $М$-чередующейся цепи)
Построим $G(M)$ (для нового $М$). Для удобства, я изображу этот граф по-другому. Поиск начнется в светлых вершинах  $x\in X$. Их только две $x_2$ и $x_3$.
Добавим все, достижимыe по светлым ребрам вершины $y\in Y$ (ход слева-направо). Получим вершины $y_2$ и $y_3$. Далее добавляем все вершины $x\in X$, достижимые по темным ребрам (ход справа-налево). Добавятся вершины $x_1$ и $x_4$. От них идем в вершины $y\in Y$, достижимые по светлым ребрам. Наткнулись на светлую вершину y из $Y$ (а их даже две). Значит поиск закончен. Остается выбрать $М$-множество. Изобразим все на картинке (рис 3)

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2032.png)

В качестве $М$-множества можно выбрать, например, такое (перечислю только вершины):
$\{p_1 = x_3, y_2, x_1, y_3; p_2 = x_2, y_3, x_4, y_4\}$. (Можно взять и другое. Какое?)
Тогда результирующим будет паросочетание (рис 4).

### Основные процедуры алгоритма Хопкрофта, Карпа.

**Построение $G(M)$.**

Удобно использовать поиск в ширину, трактуя его как волновой алгоритм.

1. Начало. Положим $V_0$ – все светлые вершины $x\in X$.
2. Движение.
Слева-направо
Все, еще непомеченные вершины $у\in Y$ , достижимые по светлым ребрам из последнего построенного фронта, который лежит в $X$.
Справа-налево
Все, еще непомеченные вершины $x\in X$, достижимые по темным ребрам из последнего построенного фронта, который лежит в $Y$.
3. Окончание. Полным построением того фронта, в котором встретится первая светлая вершина $y\in Y$.

Тогда, $G(M)$ состоит из всех помеченных в ходе поиска вершин и всех ребер, соединяющих соответствующие вершины соседних фронтов.

**Построение М-множества.** 

Вы уже знаете, что при построении всякого максимального множества главенствует принцип: «Делай пока делается». Надо беспокоится о том, чтобы разные цепи не пересекались.
Это делается легко, после построения очередной цепи все вершины и ребра удалить, а если поиск не удался, то удалить все дерево поиска.

**А почему M1, M2, …, Mk будут паросочетаниями?**
Это легко увидеть, поскольку цепи, вдоль которых происходит увеличение, не пересекаются

По этой же причине цепи $р_1, р_2, … , р_к$ будут не только $М_i$-чередующимися, но и останутся $М$-чередующимися.

# Лекция 6.

### **Оценка сложности алгоритма Хопкрофта, Карпа.**

Оценим сколько может быть М-чередующихся цепей, какова их длина, и затем количество итераций.

### Лемма 1.

Пусть $M$ и $N$ - два паросочетания в графе, и $|M| = r < s = |N|$. Тогда симметрическая разность $М \circ N$ содержит не менее s – r непересекающихся по вершинам М-чередующихся цепей.

**Доказательство.** Рассмотрим граф $G^*=(X,Y, М \circ N )$ и пусть $G_1 , …, G_k$ –  компоненты связности этого графа. Тогда, каждая вершина графа $G*$ инцидентна не более чем одному ребру из $M\setminus N$ и не более чем одному ребру из $N\setminus M$ (почему-?). Отсюда получаем, что каждая компонента связности является одним из следующих типов:

1. изолированная вершина;
2. цикл четной длины с ребрами попеременно из $M\setminus N$ и $N\setminus M$ ;
3. цепь с ребрами попеременно из $M\setminus N$ и $N\setminus M$.

Обозначим  через $Е_i$  множество ребер компоненты $G_i$. Пусть
$d_i = | Е_i ∩ N| - | Е_i ∩ M|$.

В случаях, когда компонента Gi  имеет тип 1) или 2) получаем, что $d_i = 0$.  В случае 3) либо $d_i = -1$, либо $d_i = 1$, либо di = 0. Причем случай $d_i = 1$ возможен тогда и только тогда, когда цепь начинается и заканчивается ребром из  $N$, то есть, является $М$-чередующейся.
Остается доказать, что $d_i = 1$ для не менее чем  $s – r$  индексов.
Для этого достаточно показать что сумма всех значений di не меньше  $s – r$.

Ниже все суммы берутся по $i$ от $1$ до $k$

$\sum_{1}^{k} d_i  = \sum_1^k (| Е_i ∩ N| - | Е_i ∩ M|) = (|N\setminus M | - | M\setminus N |) + |N ∩ M| - |N ∩ M| = |N| - |M| = s – r. \square$

### Лемма 3.

Пусть $М$ паросочетание в графе $G$ и  $|M| = r < s$, где $s$ – мощность наибольшего паросочетания.
Тогда существует $М$-чередующаяся цепь длины не более  $\frac{2r}{(s−r)} + 1$  .

**Доказательство.** Пусть $N$ – наибольшее паросочетание. Тогда $|N| = s$ и по лемме 1 множество $М\circ N$ содержит не менее $s – r$ непересекающихся по вершинам (а значит и по ребрам) $М$-чередующихся цепей. Пусть кратчайшая из них имеет длину $2k+1$ (длина каждой $М$-чередующейся цепи нечетна). Но, ровно $k$ ребер этой цепи принадлежат $М$. Следовательно, справедливо неравенство $(s - r) k ≤ r$.

Здесь слева в неравенстве множитель $(s – r)$ это минимально возможное число $М$-чередующихся цепей но минимум $k$ ребер в них принадлежат $М$, а число в правой части неравенства, это количество всех ребер в $М$.

Отсюда $2k + 1 ≤ \frac{2r}{(s−r)} + 1. \square$

### Лемма 4.

Пусть $р$ и $р^*$ чередующиеся цепи построенные в разных фазах алгоритма Хопркрофта, Карпа, причем цепь $р$ построена раньше, чем цепь $р^*$.  Тогда $|р|<|р^*|$.

**Доказательство.**
Достаточно рассмотреть случай, когда эти фазы непосредственно следуют друг за другом. 

Пусть $М$ и $N$ – паросочетания перед началом соответствующих фаз. Пусть $р_1, …, р_k$ $М$-множество, $r$ – длина каждой из этих $М$-чередующихся цепей.
Оценим вначале снизу длину цепи $р^*$.

Заметим, что $р = р_i$ для некоторого $i$ и $N = M \circ p_1 \circ…\circ p_k$ .
Положим $L = N \circ p^*$.
Тогда

$М \circ L = M \circ (N \circ p^*) = M \circ M \circ p_1 \circ …\circ p_k \circ p^* = p^* \circ p_1 \circ …\circ p_k = \\ р^* \circ (р_1 ∪ ... ∪ р_k )$.
Здесь мы воспользовались тем, что $М \circ М = ∅$ и тем, что цепи $р_1 ,…, р_k$ – не пересекаются по вершинам, а значит и по ребрам.

Отсюда
(1) $|M \circ L| = |p^*| + kr – 2|p^* ∩ Q|$, где $Q = р_1 \cup ... \cup р_k$  ,
поскольку длина каждой $М$-чередующейся цепи равна $r$ и их ровно $k$ штук.
С другой стороны, так как $|L| = |M| + k + 1$ и множество $M \circ L$ содержит не менее $k + 1$ реберно непересекающихся $М$-чередующихся цепей (лемма 1), получаем, что
(2) $|M \circ L| ≥ (k + 1)r$.
Из (1) и (2) вытекает неравенство
(3) $|p^*| + kr – 2|p^* ∩ Q| ≥ (k + 1)r$, то есть, получили оценку для цепи в следующей фазе
(4) $|p^*| ≥ r + 2 |p^* ∩ Q|$
Осталось показать, что $р^*$ обязательно пересекается по ребрам с каким-то $р_i$.
Так как в алгоритме Хопкрофта, Карпа выбиралось максимальное по включению множество вершинно-непересекающихся цепей, то цепь $р^*$ имеет хотя бы одну общую вершину с одной из цепей $р_1,…, р_k$ . Поскольку после каждого увеличения относительно какой-либо $М$-чередующейся цепи все вершины цепи становятся темными, эта общая вершина, назовем её $v$, не крайняя в цепи $р^*$, так как она обязана начинаться и заканчиваться в светлой вершине. Тогда темное относительно $N$ ребро, инцидентное вершине $v$, входит в обе цепи. Значит $p^* ∩ Q ≠ ∅$, то есть, $|p^*| > r. \square$

### Теорема.

Число фаз алгоритма Хопкрофта, Карпа не превышает $2 [\sqrt{𝑠} ] + 1$, где $s$ – мощность наибольшего паросочетания.
Доказательство. Пусть $М = ∅, М_1,…., М_s$ – все паросочетания, $р_0,…, р_(s-1)$  - все цепи, последовательно построенные алгоритмом, причем $М_i = М_{i-1} \circ р_{i-1}$  м
Заметим, что цепи, построенные в одной и той же фазе имеют одинаковую длину, а в разных – разную.  Таким образом, число фаз в алгоритме равно количеству различных чисел в последовательности $|p_0 |,…,|p_{s-1} |$.
Положим  $r = [s - \sqrt{𝒔} ]$  ***(!?)***
Тогда $М_r  = r < s$ . Используя лемму 3 и несложные арифметические преобразования, получим

$$

|p_r |  ≤  \frac{2r}{s−r} + 1 = \frac{2r+2𝑠−2𝑠}{s−r} + 1 = \frac{2s}{s−r} - 1 = \frac{2𝑠}{s−[𝑠 −\sqrt{𝑠} r]}  - 1 ≤ \\ ≤
 \frac{2s}{\sqrt{s}} - 1  = 2 \sqrt{s}  - 1  ≤  2 [\sqrt{s}] + 1.
$$

Поскольку длина каждой цепи нечетна, то последовательность $|р_0|,…, |р_r|$ содержит не более $[\sqrt{s}] + 1$  различных чисел.
Теперь просто посчитаем количество чисел в последовательности $|p_{r + 1}|,…,|p_{s-1} |$ .

Имеем

$(s -1) – r = (s – 1) - [s - \sqrt{s} ] ≤ (s – 1) – ((s - \sqrt{s}) – 1) = \sqrt{s}.$

Окончательно получаем, что во всей последовательности $|p_0 |,…,|p_{s-1}|$ имеется не более $2[\sqrt{s}] + 1$ различных чисел, что и завершает доказательство теоремы.

Теперь мы можем оценить вычислительную сложность алгоритма Хопкрофта, Карпа. Для заданного двудольного графа $G=(X,Y,E)$ положим $n = max(|X|, |Y|)$. Ясно, что мощность наибольшего паросочетания не превосходит  $n$ .

### Теорема Алгоритм Хопкрофта, Карпа имеет сложность $O(n^{5/2} )$.

**Доказательство**. По предыдущей теореме число фаз имеет порядок $\sqrt{𝑛}$ . Но сложность каждой процедуры в алгоритме имеет порядок $O(n^2)$ так как, для построения вспомогательного графа $G(M)$ используется поиск в ширину, а он осуществляется по матрице, каждый элемент которой приходится посмотреть, а для построения $М$–множества используется ПВГ, который имеет ту же сложность, что и ПВШ. Окончательно получаем, что сложность всего алгоритма равна

$\sqrt{n} * O(n^2)$, то есть равна $O(n^{5/2}). \square$

**Откуда взялось число r = [s - $\sqrt{𝒔}$ ] ?**

Рассмотрим функцию $f(r) = \frac{r}{s−r} +1 + (s -1 – r)$.

Подберем число число   $r$  так, чтобы функция принимала минимальное значение. Распространим определение функции $f$ на всю числовую ось, т.е, считаем $r$ вещественным числом.

Возьмем производную функции $f$  по $r$ .

Получим  $f”(r) = \frac{𝑠 − r + r}{(s−r)^2} - 1 =  \frac{𝑠}{(s−r)^2} - 1$.

Приравняем к нулю, получим $s = (s – r)^2$.    Отсюда $r = s - \sqrt{s}$.

Выберем целое значение r , лежащее рядом с найденной точкой минимума.

Подходит $r = [s - \sqrt{𝑠} ]$

# Лекция 7.

### Задача о полном паросочетании.

Пусть задан двудольный граф $G = (X,Y,E)$ (не предполагается равенства $│X│= │Y│$).

**Определение**. 

Паросочетание, у которого все вершины доли $Х$ насыщенные, назовем $Х$- полным. Насыщенная вершина = темная вершина. Просто эта терминология тоже распространена.
Паросочетание, одновременно являющееся $X$ полным и $Y$-полным называется полным (или совершенным). Разумеется, для существования полного паросочетания необходимым условием является что $|X| = |Y|$

Пусть $S$ – произвольное подмножество доли $Х$, положим $E(S)$ – все вершины доли $Y$ смежные вершинам $x \in S$.

### Теорема (Холл, 1935 г.)

В двудольном графе $G = (X,Y,E)$ $Х$-полное паросочетание существует тогда только тогда, когда для любого $S ⊂ Х$, справедливо $|S| ≤ |E(S)|$.

**Доказательство**

Необходимость проверяется элементарно (как?). С достаточностью сложнее. Я дам необычное доказательство этой теоремы, которое Вы не найдете ни в какой книге.

### Задача. В заданном двудольном графе построить Х-полное паросочетание.

**Первое решение**
Построить наибольшее паросочетание $М$ и проверить равенство $|M| = |X|$, если равенство есть, то $М$ является $Х$-полным, а если $|M| < |X|$ , то $Х$-полного паросочетания не существует.

Сложность такого алгоритма либо $O(n^3)$, если для построения $М$ используется простой алгоритм, либо $O(n^{5/2})$, если используется алгоритм Хопкрофта, Карпа.  $n = |X|$.
Главным недостатком такого метода, является то, что в случае отсутствия $Х$-полного паросочетания, мы узнаем об этом только в после завершения работы алгоритма.

**Второе решение.**
Разберем алгоритм, который завершает работу либо построением $Х$-полного паросочетания, либо в тот момент (а он может наступить достаточно рано), когда станет ясно, что $Х$-полного паросочетания не существует.

Этот алгоритм составляет существенную часть метода, разработанного Куном в 1955 году для решения более общей задачи – задачи о назначениях. Сам Кун назвал свой метод венгерским алгоритмом. Алгоритм построения $Х$-полного паросочетания будем называть алгоритмом Куна.

### Алгоритм Куна

1. Пустое паросочетание объявить текущим паросочетанием $М$.
2. Если все вершины $х\in Х$ насыщены в $М$, то СТОП ($М$ – $Х$-полно),
3. иначе, выбрать произвольную светлую вершину $х\in Х$ и искать $М$-чередующуюся 	цепь $р$,  начинающуюся в выбранной ранее вершине $х$,
4. если такая цепь р построена, то $М = М \circ р$  и на шаг 2,
5. иначе, СТОП, $Х$-полного паросочетания не существует.

В обосновании нуждается лишь шаг 5. Почему не существует полного паросочетания, если поиск из заданной, светлой вершины не приводит к построению $М$-чередующейся цепи?
Собственно именно это и является изюминкой алгоритма Куна.

Нарисуем структуру дерева Поиска. Будем считать что для поиска используется ПВГ и стартовая вершина х.

Тогда дерево имеет следующую структуру (это дерево в литературе часто называют чередующимся или венгерским).

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2033.png)

Итак, корень дерева – вершина х, следующий уровень – вершины  $y \in Y$  (шаг слева-направо  происходит по светлым ребрам, 

следующий уровень – вершины  $х \in Х$  (шаг справа –налево), и т.д.
Заканчивается дерево только в вершине типа $х$ (почему?)

### Лемма  (свойства венгерского дерева)

1. Все вершины нечетной глубины лежат в  $Y$.
2. Все вершины четной глубины лежат в $Х$.
3. Все листья в этом дереве имеют четную глубину.

Доказательство немедленно вытекает из то, что поиск $М$-чередующейся цепи из вершины $х$ окончился неудачей.

Пусть $S$ ( соответственно В) множество вершин из Х (Y), попавших в дерево поиска.
Справедлива

### Лемма

$| S | = | В | +1$, в частности  $| S | > | B |$.

Для доказательства, достаточно заметить, что вершин типа $х$ столько же сколько вершин типа $y$ на предыдущем уровне, а корневая вершина (она типа $х$) и оказывается лишней.

Для доказательства корректности алгоритма осталось показать, что $В = E(S)$, то есть, все вершины $y \in Y$, смежные вершинам $х \in S$, попадают в дерево поиска.
Прямо по определению В получаем, что $В ⊂ E(S)$.

Обратно. 

Пусть $y\in E(S)$*.  Тогда $\exist х \in S$* смежная с $y^*$.

Если $х^* = х$ ($х^*$- корневая вершина), то ребро ${х^*,y^*}$ – светлое, и по правилам поиска $y^* \in В$.

Если $х^* ≠ х$, но $х^*$ - в дереве поиска, $(х^* \in S)$, но попасть в дерево она может только после вершины  $y”$,  но $М$ – паросочетание, значит $у” = y^*$, что завершает обоснование алгоритма Куна.

### Теорема Алгоритм Куна имеет сложность $O(n^3)$.

Где $n = |X| = |Y|$.

Для поиска из произвольной вершины х очередной $М$-чередующейся цепи, используется поиск в глубину. Его сложность $O(n^2)$, всего, в худшем случае (каком?), понадобится $n$ – итераций.$\square$

## Задача о назначениях

Пусть $G = (X,Y,E,c)$ – взвешенный двудольный граф и $М$ какое-либо паросочетание в нем.
Весом (обозначение$||М||$) паросочетания $М$ назовем сумму весов входящих в него ребер, т.е., $||M|| = \sum\{c(e): e \in M\}$

Пусть $|X| = |Y| = n$.

### Задача

В заданном полном двудольном, взвешенном графе найти полное паросочетание минимального веса.

Итак граф – полный, но это ни в коей мере не ограничивает общность, ибо веса несуществующих ребер можно считать очень большими числами (например, больше чем сумма весов всех входящих в граф ребер).
Полное паросочетание минимального веса назовем оптимальным.

При изложении алгоритма буду широко использовать два языка: язык графов (французский) и язык матриц (нижегородский), там где будет удобно, будем говорить по-французски, а где-то по нижегородски .

Например, поставим задачу о назначениях на языке матриц. Всякий двудольный взвешенный граф однозначно описывается квадратной вещественной матрицей.

### Матричная постановка задачи о назначениях

В заданной квадратной матрице найти выборку минимального веса (выборка, это выбор по одному элементу из каждой строки и каждого столбца).

В самом деле, двудольный взвешенный граф однозначно описывается квадратной матрицей смежности размера $n*n$, где $n = |X| = |Y|$, а любой паросочетание $М$ задает выборку в этой матрице.

Обратно, каждая выборка в матрице определяет некоторое полное паросочетание в графе.

### Лемма 1 (по-французски)

Если веса всех ребер инцидентных одной и той же вершине графа увеличить на одно и тоже число, то всякое оптимальное паросочетание в графе с измененными весами будет оптимальным и в исходном графе.

Та же лемма по-нижегородски:

### Лемма 1’

 Если в строке или столбце заданной матрицы все числа увеличить на одно и тоже число, то всякая оптимальная выборка в новой матрице будет оптимальной и в исходной матрице.

Для доказательства достаточно заметить, что каждый элемент выборки фигурирует только один раз. Я доказываю по-нижегородски; по-французски – каждое ребро в паросочетание входит только один раз.

**Следствие 1.**  Без ограничения общности можно добавить к весу всех ребер большое число.

**Следствие 1’.** БОО можно к каждому элементу матрицы добавить большое число.

**Следствие 2.** БОО можно рассматривать графы с неотрицательными весами.

**Следствие 2’.** БОО можно рассматривать матрицы с неотрицательными элементами.

**Следствие 3. (важное)** Если в графе с неотрицательными весами найдено паросочетание нулевого суммарного веса, то оно будет оптимальным.

**Следствие 3’ (важное)** Если в матрице с неотрицательными элементами найдена выборка , состоящая из нулей, то эта выборка оптимальна.

В дальнейшем я перехожу на нижегородский язык. Рассматриваются матрицы с неотрицательными элементами

Итак, из следствия 3 следует, что двигаться надо по нулям матрицы, чтобы строить нулевую выборку. Тем самым «убивается» доказательство оптимальности!

Одну процедуру получения нулей мы сейчас опишем. Она имеет название «Редукция матрицы».

### Редукция Матрицы

1. В каждой строке матрицы найдем минимальный элемент и вычтем его из каждого элемента в этой строке.
2. Ту же операцию проделаем со столбцами.

В результате получим матрицу, в каждой строке и каждом столбце стоит хотя бы один ноль.

**Пример**

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2034.png)

Видны только ребра нулевого веса, требуется (после редукции), найти полное паросочетание в графе с нулевыми весами ребер. Используем алгоритм Куна. Считаем, что все поиски в порядке номеров вершин. Паросочетания будем нумеровать. Итак поиск ведется в следующем графе

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2035.png)

Значит полного паросочетания не существует.

Что делать? Есть еще одна операция получения нулей там где это нужно. Но ее, и весь алгоритм, разберем на следующей лекции.

# Лекция 8.

Дана 0-1 матрица, содержащая k строк и t столбцов. Для любого множества строк S этой матрицы, положим  E(S) – множество столбцов исходной матрицы, пересекающихся хотя бы с одной строкой из S по единичке.
Такое множество Х назовем полным.

### Теорема (Холл, по-нижегородски).

В 0-1 матрице множество всех строк Х является полным, тогда и только тогда, когда для любого множества строк S верно неравенство |S| ≤ |E(S)|.

**Доказательство**. По матрице построим двудольный граф G = (X,Y,Е), где доля Х – множество строк, доля Y – столбцов, а Е – единицы матрицы. Тогда, всякое Х-полное паросочетание, образует полное множество строк. И обратно. Действительно, при этих условиях, алгоритм Куна, построит Х-полное паросочетание. Иначе говоря определит, что множество строк полно. Теорема доказана.

Нижегородский вариант теоремы Холла является просто перефразировкой теоремы Холла на французском.

**Замечание**. Холл вообще доказывал свою теорему для трансверсалей. Это уже после него заметили что этот результат Холла, можно сформулировать для 0-1 матриц и для паросочетаний.

### Операция Эрегвари

Пусть $X⊂ X, Y⊂ Y$ и $d$ – некоторое число большее нуля.
Будем говорить, что к графу применена операция Эгервари, если

1. веса ребер, инцидентных $X^*$,  уменьшаются на $d$;
2. веса ребер, инцидентных $Y^*$, увеличиваются на $d$.

Схематично операцию Эгервари изображу на картинке

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2036.png)

Считаем, что $X^*$ состоит из первых p  элементов, а $Y^*$ - из первых $q$ элементов.
Тогда в регионе $I$ веса уменьшатся на  $d$, в регионе $III$ - увеличатся на $d$, а в регионах  $II$, $IV$   останутся прежними.

### Лемма 3.

Пусть к графу $G$ применена операция Эгервари, при этом
$d = min\{ c(x,y):  x \in X, y \in Y\setminus Y^* \} > 0$.

Тогда

1. Веса всех ребер графа останутся неотрицательными.
2. Веса ребер вида $xy$, где $x \in X^*$,  $y \in Y^*$ или $x \in X\setminus X^*$,  $y \in Y\setminus Y^*$ не изменятся.
3. Вес хотя бы одного ребра $x^*y^*$, где $x^* \in X$ , а  $y^* \in Y\setminus Y^*$ станет равным нулю.

**Доказательство.** 

Очевидно! (Если смотреть на матрицу, и ужасно, если смотреть на граф).

Веса ребер вида xy, где $x \in X^*,  y \in Y^*$ или $x \in X\setminus X^*,  y \in Y\setminus Y^*$ лежат в регионах $II$  и $IV$.
Вес хотя бы одного ребра $xy$, где $x^* \in X$, а  $y^* \in Y\setminus Y^*$ станет равным нулю, так как
$d = min\{ c(x,y):  x \in X ,y \in Y\setminus Y^* \} > 0$, и это регион $I$.

Веса останутся неотрицательными, так как в регионе $III$ они только увеличатся, а в регионах $II$, $IV$ ничего не происходит, а регионе $I$ вычитается минимальный элемент.

### Венгерский алгоритм решения задачи о назначениях

Полный, двудольный, взвешенный граф $G = (X, Y, E, c)$ задан неотрицательной матрицей весов

1. Осуществить Редукцию матрицы весов.
2. Пустое паросочетание объявить текущим, $М = \empty$.
3. Если в графе все вершины насыщены относительно текущего паросочетания  М,
то СТОП, М – оптимальное.
4. Иначе, выбрать произвольную светлую вершину $х \in Х$ и искать М-чередующуюся цепь, которая  начинается в вершине $х$ и состоит из ребер нулевого веса.
5. Если такая цепь р построена, то положить $М = М \circ р$ и вернуться на шаг 3.
6. Иначе, для множеств $X^*⊂ X,  Y^* ⊂ Y$, помеченных в ходе поиска (это вершины 	венгерского дерева), положить $d = min\{ c(x,y):  x \in X^* ,  y \in Y\setminus Y^* \}$ и применить к графу 	операцию Эгервари.
7. Из тех вершин $х \in Х^*$, которым стало инцидентным ребро нулевого веса, продолжить 	поиск М-чередующейся цепи, используя только ребра нулевого веса.
8. Осуществлять шаги 6 и 7 до тех пор пока не будет построена М-чередующаяся цепь р.
9. Положить $М = М \circ р$ и вернуться на шаг 3.

### Теорема

Венгерский алгоритм правильно строит паросочетание нулевого веса.

**Доказательство.** 

Итак, $M_0  = \empty$, и значит вес паросочетания $M_0$ равен нулю. На каждом шаге алгоритм ищет М-чередующуюся цепь, состоящую только из ребер нулевого веса. Поскольку симметрическая разность не меняет веса ребер, то новое паросочетание будет нулевым. Но там же есть операция Эгервари. А как обстоят дела с ней, ведь кое-где эта операция увеличивает веса ребер и нули могут пропасть?

Пусть  $X⊂ X,  Y ⊂ Y$, все вершины, помеченные в ходе поиска из вершины х, и поиск не находит М-чередующейся цепи и пусть ребро $xy \in М$ (М – текущее паросочетание, то, которое было перед неудачным поиском из вершины $х$).
Тогда, поскольку ребро $x^*y^*$ темное, то $x^* ≠ х$ (поиск начинается в светлой вершине). Возможны два варианта: $x^* \notin X^*$ и $x\in X$. Но $x^*$ может попасть в дерево поиска только после $y^*$.

1. Пусть $x^* \notin X^*$, тогда и $y^* \notin Y^*$, т.е., вес ребра $с(x^*y^*)$ входит в регион $IV$, а там ничего не происходит.
2. Пусть $x^*\in X$, тогда и $y^* \in Y^*$, т.е., вес ребра $с(x^*y^*)$ входит в регион $II$, а там нули сохраняются.

Заметим, что в регионе $I$ все элементы больше нуля, так как в противном случае алгоритм бы продолжил поиск М-чередующейся цепи.

Значит $d = min\{ c(x,y): x \in X^*, y \in Y\setminus Y^* \}>0$ и в регионе $I$ действительно появится ноль, и значит поиск можно продолжить.
Поиск, в конце-концов закончится построением М-чередующейся цепи, ибо в противном случае поиск продолжается, а граф конечен! $\square$

**Разберем пример из  прошлой лекции**

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2037.png)

Видны только ребра нулевого веса, требуется (после редукции), найти полное паросочетание в графе с нулевыми весами ребер. Используем алгоритм Куна. Считаем, что все поиски в порядке номеров вершин. Паросочетания будем нумеровать. Итак поиск ведется в следующем графе

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2038.png)

Значит поиск из $x_3$ не приводит к построению М-чередующейся цепи.

Тогда $X^* = \{x_1 ;  x_2 ; x_3 \}, Y^* = \{y_1 ; y_2 \}$ . 

Осуществим операцию Эгервари.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2039.png)

Возобновим поиск из вершины $x_3$. Сразу будет найдена М-чередующаяся цепь $x_3 \leadsto y_3$.
Новое паросочетание  $M_3$  станет таким  $M_3 = \{x_1  y_2 ; x_2  y_1 ; x_3  y_3\}$ .

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2040.png)

Окончательно, получим $М = M_4= \{x_1  y_2 ; x_2  y_1 ; x_3  y_3 ; х_4 у_4 \}$ .
Вес найденного паросочетания $||M|| = 12$  (считать надо по исходной матрице).

### Теорема Венгерский алгоритм имеет сложность $O(n^4)$.

(так изложенный (что за хрень?))

**Доказательство**. Такая оценка возникает из-за того, что операцию Эгервари нужно делать порядка n раз, а сложность одной итерации порядка $n^2$  и всего нужно делать n  итераций.
Известна реализация венгерского алгоритма со сложностью $O(n^3)$. Детали в моей книге

# Лекция 9.

## Задача о разбиении на наименьшее число паросочетаний.

**Пример**

В школе имеется n учителей $p_1,..., p_n$  и k классов $x_1.,..x_k$.
Каждый $i$ учитель, в неделю, должен провести в $j$ классе $q_{ij}$ уроков (большинство  $q_{ij}$ равно нулю)
Требуется составить расписание уроков на неделю, минимизирующее максимальное число уроков у самого загруженного класса.

Построим двудольный мультиграф (граф называется мультиграфом, если некоторые вершины в нем, соединены более чем одним ребром). Левая доля – все учителя, правая – все классы; пара $(i,j)$, где $i$ учитель, а $j$ класс, соединена $q_{ij}$ ребрами.
Заметим , что расписание на один урок – это паросочетание, так как в одном и том же классе не могут быть два учителя, и один и тот же учитель не может одновременно вести уроки в разных классах.

Отсюда получаем следующую задачу. Разбить множество ребер на наименьшее число паросочетаний.

Надо именно все ребра включить в паросочетания, поскольку учебный план надо выполнять!

### Постановка задачи

Пусть $G = (X,Y,E)$ – двудольный мультиграф.
Требуется разбить множество ребер на множества $М_1,…,М_k$ так, чтобы

1. $М_i$ – паросочетания для всех $i = 1,…,k$;
2. $М_i ∩ М_j = ∅$;
3. $∪ \{М_i : i = 1,…,k\} = Е$;
4. $k$ – минимально с таким свойством.

Оценим снизу минимальное число паросочетаний

### Лемма.

Пусть R – максимальная степень вершины в мультиграфе G, тогда k ≥ R.
Для доказательства достаточно заметить, что в каждое паросочетание из разбиения входит не более одного ребра, смежного вершине с наибольшей степенью.
Отсюда получаем
**Следствие (важное)**. Всякий алгоритм, который разбивает ровно на R паросочетаний, где R – максимальная степень вершины в мультиграфе G оптимально, по числу паросочетаний.
Осталось предъявить такой алгоритм.
Все последующее я узнал от своего студента Олега Меркурьева.
Я строил алгоритм и доказывал корректность через теорему Мендельсона, Далмеджа и каждый раз маялся от того, что студенты ничего не понимали, а О. Меркурьев делает очень просто и надеюсь студентам будет понятно.

**Определение.** Граф называется регулярным, если степени всех вершин одинаковы.

### Теорема

В регулярном двудольном мультиграфе существует полное паросочетание.

**Доказательство**

Для доказательства потребуется аналог теоремы Холла, но на этот раз для мультиграфов. Поскольку изменений практически не будет, но вы, в массе своей, продемонстрировали полное непонимание  этой теоремы, и кроме того, Холл не доказывал свою теорему не в этой формулировке, то я заново сформулирую и докажу эту теорему.

**Теорема (Холл, 1935)**. В двудольном мультиграфе $G = (X,Y,E)$ $Х$-полное паросочетание существует тогда только тогда, когда для любого $S ⊂ Х$, справедливо $|S| ≤ |E(S)|$.
Здесь, через $E(S)$ обозначено множество вершин в $Y$ инцидентных вершинам $х \in S$.

*Необходимость*. Пусть существует $Х$-полное паросочетание. Обозначим его $М$. Пусть $S$ – произвольное подмножество $Х$. Тогда каждая вершина х из S инцидентна, по множеству $М$, одной вершине $у\in У$. Значит $|S| ≤ |E(S)|$, поскольку в $E(S)$ могут быть и другие вершины из $У$.

*Достаточность.* Пусть для любого $S ⊂ Х$, справедливо |$S| ≤ |E(S)|$. Применим алгоритм Куна построения паросочетания. Алгоритм не меняется от того что рассматриваются мультиграфы. Все равно надо начинать в светлой вершине, правила движения не меняются (слева-направо по светлым ребрам, справа-налево по темным) и т.д.. Но алгоритм Куна может не найти М-чередующуяся цепь только в том случае, когда построено множество $S$ из $Х$  такое, что $|S| > |E(S)|$ , а у нас таких множеств не существует! Теорема доказана.

Теперь у нас все готово для доказательства основной теоремы (в двудольном регулярном мультиграфе существует полное паросочетание)
**Доказательство**. Покажем, что для любого $S ⊂ Х$, справедливо $|S| ≤ |E(S)|$ (для $S ⊂ У$ аналогично).

Пусть в $S - q$ элементов, в $E(S)$ – р элементов и $r$ – максимальная степень вершины, посчитанная в графе $Г = (S,E(S), Е^*)$, где $Е^*$ ребра из графа $G$. Требуется доказать, что $q ≤ p.$ Посчитаем количество ребер между $S$ и $E(S)$. Посчитаем вначале относительно множества $S ⊂ Х$. Ясно, что это число равно $q^*r$*.* С другой стороны (считаем относительно *$У$),* оно не меньше чем *$p^*r$*, так как вершины $у \in E(S)$ могут быть смежны вершинам не входящим в $S$. Отсюда $q^*r ≤ p^*r$, откуда и получаем неравенство $q ≤ p$. Теорема доказана.

### Алгоритм (О. Меркурьев)

Разбиение на наименьшее число паросочетаний.

1. Добавить в заданный мультиграф вершины и ребра так, чтобы он стал регулярным со степенью	вершин $r$, где $r$ – максимальная степень вершины в исходном графе.
2. Положить $k = r$
3. Пока $(k > 0)$
Начало цикла. Построить полное паросочетание $М$, положить $M = Mk$,
удалить из М все добавленные ребра.
Положить $k = k – 1$.
Конец цикла.

Корректность алгоритма очевидна, поскольку степень вершин в мультиграфе понижается на 1.

Вернемся к тому с чего началась сегодняшняя лекция.

Итак, требуется составить школьное расписание.
Что будет с человеком, который применит этот алгоритм?
В лучшем случае его уволят. За профнепригодность.
Почему?
Предложенная схема составления расписания очень плохая.
Главным образом потому, что занятия разные да и учителя тоже.
если в 1 классе двенадцать уроков, то ничто не мешает поставить в понедельник и во вторник несчастным первоклассникам поставить по 6 уроков день;
ничто не мешает поставить «окна» в расписании;
ничто не мешает поставить в один день 6 уроков математики;
есть страстные садоводы и они категорически отказываются работать в школе в субботу;
и т.д. и т.п.

Что делать? Решать надо сведением к задаче о потоке минимальной стоимости, но ставить очень большой человеческий блок.

Вообще задачи теории расписания очень сложные.

## Связь потоков и паросочетаний в двудольных графах.

Пусть $G = (X,Y,E)$ – двудольный граф.

Построим сеть $G^* = (V,E,c)$ положив
$V = \{s\} ∪ X ∪ Y ∪ \{t\}$
$A[s,x]=A[y,t] = 1$ для всех $x$ и $y$ из $X ∪ Y, A[x,y] = 1$ тогда и только тогда, когда x и y соединены ребром в G.
$с[s,x] = c[y,t] = 1, c[x,y] = 1$, если ребро x,y имеется в сети и $c[x,y] = 0$ в противном случае.
Пример.

![Граф $G = (X,Y,E)$](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2041.png)

Граф $G = (X,Y,E)$

![](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2042.png)

Сеть $G^* = (V,E,c)$
В сети $G^*$ пропускные способности всех ребер равны 1

Обозначим $P$-множество всех паросочетаний в графе $G$, а $F$ – множество всех $(0-1)$ потоков в сети $G^*$.

### Теорема.

Существует взаимно-однозначное отображение $\phi$ множества $P$ на множество $F$ , причем$|M| = || \phi(M)||$ для любого паросочетания $М$ в $G$.

**Доказательство**. Пусть $М$ произвольное паросочетание в $G$. Построим поток $\phi(M)$ в $G^*$. 

Положим $\phi(M)(s,x) = \phi(M)(x,y) = \phi(M)(y,t) = 1$ для всех ребер $xy\in М$, и $\phi(M)(е) = 0$ для остальных ребер $е \in Е$.
Покажем, что $\phi(M)$ – является потоком в $G^*$.
Поскольку, по построению, $\phi(M)$ принимает лишь значения 0 или 1, а пропускные способности все не больше 1, то условие ограничения по пропускной способности выполняется.
Проверим условие сохранения потока во всех вершинах кроме $s$ и $t$.

Пусть $х^*$ – темная вершина в паросочетании $М$. Тогда $\phi(M)(s,x^*) = 1$, то есть, поток, втекающий в $х^*$ равен 1. Но М – паросочетание, значит существует только одно ребро $х^*у^*$ лежащее в $М$, но тогда и $\phi(M)(х^*,у^*) = 1$ только на одном ребре. Значит $\phi(M)(х^*-) = \phi(M)(х^*+) = 1$.

Пусть $х^*$ - светлая вершина относительно $М$. Тогда $\phi(M)(х^*-) = \phi(M)(х^*+) = 0$.
Для вершин $у \in Y$ проверка выполняется аналогично.
Поскольку количество темных вершин из $Х$ равно $|M|$, то $\phi(M)(s+) = |M|$.
Итак, отображение $\phi$ инъективно (то есть, «в»), и $|| \phi(M) || = |M|$.

Покажем, что отображение  $\phi$ сюръективно (то есть «на»).
Пусть $f$ – произвольный $(0-1)$ поток в $G^*$. Построим паросочетание $\phi(M)$ такое, что $\phi(М_f) = f$.
Для этого положим $М_f = \{xy: f(x,y) = 1\}$. Поскольку в каждую вершину х из Х входит только одно ребро, то, значит $f(s,x) = 1$ для не более одного ребра. Так как $f$ – поток, то $f(x+) = f(x-)$ и значит не более чем на одном ребре вида $ху$ поток равен 1. Но только одно ребро ведет из $у$ в $t$ и опять таки условие, что в поток, обеспечивает то, что втекающий в у поток не больше 1, а значит и вытекающий, то есть  – $М_f$ паросочетание.
Так построенное отображение φ является обратным к построенному ранее отображению.
Ясно, что $||f|| = | М_f |$. Теорема доказана.

Легко видеть, что понятие М-чередующейся цепи соответствует понятию 
$f$-дополняющей $(s,t)$ - цепи.

Задача о наибольшем паросочетании может быть легко сведена к задаче о максимальном потоке, а задача о полном паросочетании – к потоку заданной величины $|X|$.

Сложнее обстоит дело с задачей о назначениях.

# Лекция 10.

## Труднорешаемые задачи

Задача называется легкорешаемой, если известен алгоритм её решающий с полиномиальной оценкой сложности.

**Определение.**

Задача называется труднорешаемой, если такой алгоритм неизвестен.

Класс легкорешаемых задач обозначается $P$, с классом труднорешаемых задач сложнее, выделяется класс полиномиально распознаваемых: $NP$, в  частности,  $P ⊂ NP$ .

Одна из крупнейших проблем математики, сформулированная в 1971 году Куком, формулируется так: верно ли, что справедливо равенство $P = NP$?

Задачи, которые мы рассматривали до сих пор, относятся к классу $Р$, между тем, как подавляющее большинство практически важных задач – к классу $NP$. Зачем мы это делаем? Просто алгоритмы, которые в массе своей разрабатываются для труднорешаемых задач, как правило, основаны на алгоритмах решения легкорешаемых задач.

В классе $NP$  выделяется подкласс $NP$-полных задач, то есть таких, к которым полиномиально сводятся все задачи  класса $NP$.

Достаточно решить одну (!) $NP$-полную задачу и тогда будут решены все задачи класса $NP$-полных, тем самым будет показано, что $P = NP$, а автор получит 1 миллион долларов от института Клея.

Мы привыкли к тому что все задачи формулируются как оптимизационные, в то время как в теории $NP$-полных задач удобнее формулировать задачи как задачи распознавания. Можно доказать, что задачи распознавания ничуть не проще чем оптимизационные. 

### NP-полные задачи

Доказано, что следующие задачи NP- полны.

1. ГАМИЛЬТОНОВ ЦИКЛ. 
Дан граф $G$. 
Определить, содержит ли граф $G$ гамильтонов цикл.
2. ВЕРШИННОЕ ПОКРЫТИЕ. 
Даны граф $G = (V,E)$ и натуральное число $k$. 
Определить, существует ли в графе $G$ вершинное покрытие мощности не более $k$.
Множество $A ⊂ V$ называется вершинным покрытием, если для любое ребро $e \in E$ инцидентно какой-либо вершине $w \in А$.
3. ДОМИНИРУЮЩЕЕ МНОЖЕСТВО. 
Даны граф $G = (V,E)$ и натуральное число $k$. 
Определить, существует ли в графе $G$ доминирующее множество мощности не более $k$.
Множество $A ⊂ V$ называется доминирующим, если для любая $v\notin A$, смежна какой-либо вершине $w\inА$.
4. КЛИКА. 
Даны граф $G = (V,E)$ и натуральное число $k$.
Определить, содержит ли граф $G$ клику мощности $k$.
Множество $A ⊂ V$ называется кликой, если любые две входящие в него вершины смежны.

И т.д. и т.п., известно на сегодня, что класс NP-полных задач содержит несколько сотен.

### Способы решения труднорешаемых задач

Вот моя классификация возможных подходов.

1. Эвристические алгоритмы.  
Это наукобразное название «алгоритмов от балды», иначе говоря алгоритмы, которые, во многих случаях, дают правильный ответ, но могут его не дать.
2. Алгоритмы с гарантированной оценкой точности. 
Оказывается во многих случаях, не находя точного решения, можно показать что найденное решение не более чем в k раз превосходит оптимальное. Точные определения я дам позже.
3. Частные случаи. 
Зачастую оказывается, что случай является частным, а там находится оптимальный алгоритм.
4. Стохастические алгоритмы
    
    Это тоже наукообразное название, за которым стоит, правда, большой смысл. До сих пор мы рассматривали только детерминированные алгоритмы, т.е.,  алгоритмы, которые при одних и тех же начальных данных, но при разных запусках, давали один и тот же результат. Здесь мы познакомимся с методом, который при разных запусках дает разные ответы. 
    
5. Точные методы 
Я не знаю других методов поиска точного решения, кроме метода ветвей и границ. Применять этот метод можно только тогда, когда задача исключительно важна, и решение займет не слишком много времени (компьютер – железяка, пусть работает!)

### Задача Вершинного покрытия

Напомню, множество вершин $A$ называется вершинным покрытием, если всякое ребро графа инцидентно хотя бы одной вершине из множества $А$.

В задаче требуется найти минимальное множество, являющееся вершинным покрытием.

**Эвристический алгоритм.**

Последовательно выбирать вершину наибольшей степени из оставшихся, добавив ее в строящееся множество, и удалить все ребра ей инцидентные.

Алгоритм легко реализовать так, чтобы он имел сложность $O(n^2)$. Алгоритм похож на правдивый.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2043.png)

Здесь алгоритм сразу возьмет вершину 1 и закончит построение вершинного покрытия. Ответ правильный

---

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2044.png)

Здесь алгоритм может выбрать вершину 3, дальше алгоритму не останется выбора и он должен взять по одной вершине из 1 и 2, и 4 и 5. То есть, алгоритм построил вершинное покрытие из 3-х элементов, хотя оптимально выбрать из 2-х.

---

Но этот алгоритм может давать и очень плохие результаты. Вот еще один пример. 

Рассмотрим трехдольный граф (на самом деле он двудольный, но мне удобнее именно так излагать) $G = (X,Y,Z,E)$. Пусть $k$ –натуральное число, положим в $Х - k – 2$ элемента, в  $Y$ и $Z$ по $k$ элементов. Множество ребер $Е$ определим так. Каждая вершина $Х$ соединена с каждой из $Y$, каждая $i$-ая в $Y$ соединена с $i$–ой в $Z$. На рисунках (слева $k$ произвольно, справа $k = 3$)  это выглядит так:

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2045.png)

Здесь степень каждой вершины из $Х$ равна  $k$, а степень каждой из $Y$ -  $k-1$. Алгоритм выберет на первом шаге вершину $x_1$, удалит все ребра инцидентные $x_1$; затем возьмет x2 и т.д. . Т.е. выбрано будет все множество $Х$, останутся ребра между $Y$и $Z$ , таковых останется еще $k$.
Итого будет выбрано $(k -2) +  k$ , т.е., $2k -2$ элементов, в то время как минимальное вершинное покрытие равно $k$ (все вершины из $Y$).

### Алгоритмы с гарантированной оценкой точности.

Пусть решается класс задач $В$ на поиск minimum. Имеется ввиду массовая задача. Например, в заданном графе найти минимальное вершинное покрытие.
Говорят, что некий алгоритм $А$ имеет гарантированную точность $k$, если для любой индивидуальной задачи класса $В$ справедливо неравенство $||А(G)|| \leq k^*||Opt(G)||$,
здесь, $А(G)$ – решение, найденное алгоритмом $А$, $Opt(G)$ – оптимальное решение,
$||А(G)||$ , $||Opt(G)||$ -  их веса.
При этом мы не знаем оптимального ответа, но можем его оценить.

Рассмотрим следующий алгоритм. Пусть $G = (V,E)$ – произвольный граф.
АЛГОРИТМ «ВЕРШИННОЕ ПОКРЫТИЕ»

1. Положим С = ∅, сформировать из E ОЧЕРЕДЬ в произвольном порядке.
2. Пока (ОЧЕРЕДЬ ≠ ∅)
3. НЧЛ цикла. Считать из ОЧРД ребро е, удалить е из ОЧРД,
если е ∩ С = ∅ (ни одна вершина из е = v,w не попадает в С),
то добавить обе вершины в С.
4. КНЦ цикла.

### Теорема. Алгоритм «Вершинное покрытие» имеет точность 2, а сложность $O(m)$.

**Доказательство.** Пусть $М$ – наибольшее паросочетание, хотя бы одна из вершин произвольного ребра из $М$ должна попасть в вершинное покрытие. Оптимальное решение может состоять из одной вершины произвольного ребра, а может из двух. Отсюда получаем неравенство
$||А(G)|| ≤ 2^*||Opt(G)||$, где через $А$ обозначен алгоритм «Вершинное покрытие», $A(G)$ – вершинное покрытие, построенное алгоритмом для графа $G$, $||А(G)||$ - вес решения; естественно считать, что вес равен мощности вершинного покрытия $А(G)$.
Придется смотреть все ребра. их m-штук, отсюда и сложность $O(m)$. Анализ того, что входят ли вершины в множество $C$ имеет сложность $О(1)$. Теорема доказана.

Обе крайние оценки точности алгоритма достижимы. Примеры.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2046.png)

### Частные случаи.

Оказывается для двудольных графов есть полиномиальный алгоритм, более того мы его изучали!
Это алгоритм Хопкрофта, Карпа!
Пусть $G=(V,E)$ –  произвольный граф. В теории графов приняты следующие обозначения.
Число вершинного покрытия, то есть, количество вершин в наименьшем вершинном покрытии, обозначается как $\beta_0(G)$, а число паросочетания, то есть, количество ребер в наибольшем паросочетании - $\alpha_1(G)$.

**Теорема** 

В произвольном двудольном графе $G = (X,Y, E)$ число вершинного покрытия $\beta_0(G)$ равно числу паросочетания  $\alpha_1(G)$.
**Доказательство.** Докажем вначале неравенство $\alpha_1(G) \leq \beta_0(G)$ (т.е. число паросочетания не больше числа вершинного покрытия). Пусть $М$ –произвольное паросочетание, а $С$ – произвольное вершинное покрытие. Для каждого ребра $е = vw$ из $М$ через $f(e)$ обозначим ту вершину, которая входит в $С$, если обе входят, то одну из них (любую). Поскольку $М$ – паросочетание, то $f(e) ≠ f(g)$, если ребра e и g различны, иначе говоря отображение
$f: M \rightarrow C$ является инъективным вложением $M$ в $С$. При этом $|M| = |f(M)| ≤ |C|$, так как в $С$ могут быть еще и другие элементы. Следовательно, любое вершинное покрытие содержит не меньше вершин, чем количество ребер в любом паросочетании. Отсюда $\alpha_1(G) ≤ \beta_0(G)$ .

Заметим, что это неравенство доказано для произвольных графов, а не только для двудольных.

Докажем обратное неравенство. Пусть $М$ – наибольшее паросочетание в двудольном графе $G$. Пусть $e = ху$ произвольное ребро из $М$. Назовем вершину у отмеченной, если существует $М$ –цепь, оканчивающаяся в $у$ (лекция 5), в противном случает считаем вершину $х$ отмеченной.

Цепь $р$ называется  $М$-цепью, если выполняются два условия:
начальная вершина $x_0$ – светлая,
цвета ребер чередуются по правилу: светлое-темное и цепь имеет нечетную длину, то есть заканчивается в вершине $у \in Y$.

Множество всех отмеченных вершин обозначим через $С$. Из построения следует, что
$|М| = |С|$.
Убедимся, что множество С является вершинным покрытием.
Пусть е = ху произвольное ребро графа $G$ и $х \notin С$. Проверим, что тогда $у \in С$. Возможны 2 случая.

1. Ребро $е$ – темное. Тогда, прямо по построению, $у \in С$.
2. Ребро $е$ – светлое.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2047.png)

---

2.1. Вершина $х$ – светлая, тогда вершина $у$ – темная, так как $М$ – наибольшее паросочетание, а иначе цепь $р: х, у$ была бы $М$ - чередующейся, что невозможно. Но тогда $р$ это $М$-цепь, и значит $у ∈ С$ поскольку $у$ – темная, значит инцидента некоторому ребру $е^*=х^*у$ из $М$, и при рассмотрении ребра $е^*$ вершину $у$ мы отметили, то есть считаем ее	принадлежащей $С$ ( на рисунке отображен именно этот случай, то есть, при	рассмотрении цепи $ху$ вершина $у$ отнесена в $С$). Итак, в этом случае, $у \in С$.

---

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2048.png)

---

2.2. Вершина $х$ – темная. Тогда существует ребро $е^* = ху^* \in М$. Но, по предположению, $х \notin С$, значит, $у^* ∈ С$, то есть существует $М$-цепь, оканчивающаяся в $у^*$. Обозначим эту цепь через $q$. Но тогда цепь $q ∪ \{у^*х\} ∪ \{x,у\}$ является $М$-цепью, канчивающейся в $у$. Следовательно, $у \in С$, что и требовалось доказать. На рисунке изображен этот случай.

**Построение наименьшего вершинного покрытия.**
Возьмем последнюю итерацию алгоритма Хопкрофта, Карпа, то есть, где $G(М) = \empty$ и пусть $Х^*$ и $Y^*$ все вершины из $Х$ и $Y$, помеченные в ходе поиска $М$-чередующейся цепи. Оказывается $С = (Х\setminusХ^*) ∪ Y^*$ (!).
В самом деле, пусть ребро $е = ху$ произвольное темное. Если  вершина $у$ помечена в ходе поиска, то по правилам помечивания, в $у$ заканчивается некоторая $М$-цепь, и значит $у \in С$.
Если $у$ не помечена в ходе поиска, то и $х$ не помечена, так как вершины $х$ помечаются после вершин типа $у$, им инцидентных, то есть, $х ∈ Х\setminusХ^*$ , что завершает доказательство равенства $С = (Х\setminusХ^*) ∪ Y^*$ .

# Лекция 11.

## Задача коммивояжера

Бесспорно, самой популярной задачей дискретной оптимизации является задача коммивояжера. Есть несколько различных формулировок этой задачи. Я буду придерживаться такой.

Пусть $G = (V,E,c)$ – неориентированный, полный, взвешенный граф. 

Цикл графе $G$, включающий каждую вершину ровно по одному разу называется маршрутом коммивояжера. 

Внимательный читатель, конечно заметил, что это определение Гамильтонова цикла.

Отличие от книги состоит в том, что там рассматривается на копейку более общая задача в ориентированном графе. Но все содержательные результаты относятся именно к неориентированным. Поэтому я ими и ограничусь.

### Постановка задачи.

В заданном полном, взвешенном неориентированном графе найти маршрут коммивояжера минимальной стоимости.

При этом стоимость маршрута коммивояжера равна сумме стоимостей входящих в маршрут ребер.

В дальнейшем задачу коммивояжера будем обозначать ЗК.

Задать полный взвешенный граф, все равно что задать квадратную симметричную матрицу по диагонали, которой стоят нули. Маршрут коммивояжера, это просто выборка по одному элементу в каждой строке и каждом столбце в такой матрице. Таким образом ЗК (по нижегородски) – это просто найти выборку с минимальной суммой.

Но и задача назначения, в двудольном графе, это тоже поиск выборки с минимальной суммой в квадратной матрице. Почему, задача назначения легкорешаема а ЗК труднорешаема?

Не спасает тут и апелляция к тому, что рассматриваются симметричные матрицы, можно решать ЗК и в ориентированном полном графе, тогда матрица весов не обязана быть симметричной. Нули по главной диагонали тоже не играют роли, всегда можно рассматривать матрицы, у которых по диагонали стоят здоровенные числа.

Проблема здесь в том, что маршрут коммивояжера - это выборка, но не всякая выборка является маршрутом коммивояжера. Именно в этом и состоит отличие ЗК от задачи назначения.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2049.png)

Вначале сформулируем и докажем теорему не существования

### Теорема не существования.

Если $P ≠ NP$, то не существует полиномиального алгоритма, решающего ЗК с гарантированной оценкой точности $k$.

**Доказательство**. Предположим противное, что такой алгоритм существует, обозначим его за $А$. Пусть алгоритм $А$ имеет точность $k$, то есть, для любого неориентированного, полного, взвешенного графа $G$ справедливо неравенство $|| А(G) || ≤ k^*|| Opt(G) ||$.

Покажем тогда, что этот алгоритм $А$ решает задачу о Гамильтоновом цикле, что противоречит предположению $P ≠ NP$, так как задача о Гамильтоновом цикле $NP$-полна.

Напомню задачу о Гамильтоновом цикле. В заданном графе построить Гамильтонов цикл или вывести сообщение, что его не существует.

Пусть $Г$ – произвольный граф. Зададим неориентированный, полный, взвешенный граф $G$. Множество вершин графа $G$ то же, что и в графе $Г$. Граф полный, следовательно, ребра описывать не надо, веса ребер определим так

$$c(v,w) = \begin{cases}$ 
$1, v,w \in Г \\$
$kn, v,w \notin Г$
$\end{cases}$$

Пусть к графу $G$ применен алгоритм $А$. Посмотрим на длину маршрута, построенного $А$. Если длина маршрута $А(G)$ строго больше чем $n$, то в маршрут $А(G)$ попало хотя бы одно ребро, не входящее в граф $Г$. В самом деле, справедлива цепочка неравенств
$||Opt(G)|| ≥ || А(G) || /k > \frac{n}{k} > n$, так как $k > 1$.
То есть в $Г$ нет Гамильтонова цикла.

Но верно и обратное, пусть в $Г$ нет гамильтонова цикла, тогда $Opt(G)$ включает хотя бы одно ребро не из $Г$, следовательно, и $А(G)$ включает в себя хотя бы одно ребро не из $Г$, поскольку $|| А(G) || ≥ ||Opt(G)||$.

Итак, вес маршрута $А(G)$ определяет есть или нет в $Г$ гамильтонов цикл, что завершает доказательство.

Итак, алгоритма с гарантированной оценкой точности в общем случае, не существует.

**Определение.** Граф, матрица весов которого симметрична, неотрицательна и удовлетворяет неравенству треугольника, называется метрическим.
Иначе говоря, метрический граф, это такой, что веса ребер удовлетворяют аксиомам метрики.
Функция $d(x,y)$ называется метрикой на пространстве $Х$, если она удовлетворяет условиям

1. $d(x,y) = 0$ тогда и только тогда, когда  $x = y$;
2. $d(x,y) = d(y,x)$;
3. $d(x,y) ≤ d(x,z) + d(z,y)$ для всех $x, y$ и $z$.

## Эвристический алгоритм

**Алгоритм Ближайший Сосед.**

1. Произвольную вершину считать первой и последней добавленной.
2. На каждом шаге идти в ближайшую к последней добавленной.
3. Как только все вершины в маршруте, идти в первую.

Алгоритм «Ближайший сосед» легко реализовать так, чтобы он имел сложность $O(n^2)$.
Понятно, что в общем случае, за счет последнего ребра, можно получить хоть какую оценку. Вот пример

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2050.png)

---

Здесь задан полный граф на 4 вершинах, веса ребер (1,2); (2,3) и (3,4) равны 1, а на ребрах (1,3) и (2,4) – 2; и, наконец, на ребре (1,4) вес равен $К$, где $К$ большое число.

---

Тогда Ближайший сосед, с началом в вершине 1, последовательно включит в маршрут вершины 2, 3 и 4, а затем ничего не остается как по ребру (1,4) прийти в вершину 1. Вес такого маршрута будет $К + 3$, где число $К$ сколь угодно большое.

Однако и для метрических графов оценка точности неважная.

### Теорема.

Пусть $А$ алгоритм Ближайший сосед. Тогда, для любого метрического графа $G$ справедливо неравенство$|| А(G) || ≤ ([ logn ] + 1)||Opt(G)||.$

Результат очень плохой, так как множитель, стоящий в этом неравенстве справа, стремится к бесконечности. Ценится именно константа, чем ближе к единице, тем лучше.

Однако, это оценка сверху, и ничего не говорится о то, насколько плохим может быть решение. Оказывается, есть примеры, когда ответ реально плох, а именно, справедливо неравенство $*|| А(G) || > \frac{1}{3} logn ||Opt(G)||*$.

Хотя теоретически этот алгоритм бесконечно плох, но в реальных случаях он весьма неплох, особенно для метрических графов.

Теорему привожу без доказательства.

# Лекция 12.

## Алгоритмы с гарантированной оценкой точности

Можно получить оценку точности, лишь чуть подправив алгоритм Ближайший сосед.

Пусть $G = (V,E,c)$ – какой-либо взвешенный граф (не обязательно полный и не обязательно метрический) , пусть $F ⊂ V$ и $v \in V$.

Введем следующие обозначения.

$d(v,F) = min \{c(v, w): w \in F\}$ – число, которое естественно назвать расстоянием от вершины v до множества $F$;

$v(F)$ - вершина, на которой достигается минимум расстояний до $F$, среди всех вершин, не входящих в $F$, то есть $d(v(F)) = min \{ d(v): v \notin F \}$. Вершину $v(F)$ естественно называть ближайшей к $F$

В других разделах математики $v(F)$ называют элементом наилучшего приближения элементами $F$, впрочем, в школе называли этот элемент перпендикуляром из $F$.

$pv(F)$ - проекция $v$ на $F$, т., е,  $c(v,pv(F)) = d(v(F),F)$. 

На картинке введенные обозначения можно изобразить так

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2051.png)

### Алгоритм ближайшая вставка

Вход: неориентированный, полный взвешенный граф $G = (V,E,c)$ (не важно, как он задан)

Используемые переменные: массив $БЛЖ$, где $БЛЖ[v] = p(F)$, здесь $F$ – вершины,
входящие в текущий маршрут, $v \in V$.

Выход: маршрут коммивояжера T, заданный массивом $СЛЕД$, где $СЛЕД[v]$ – имя
вершины, следующей за $v$ в МК (МК обозначим $Т$, в алгоритме не понадобится).

```sql
1. begin
2. F = {w}; СЛЕД [w] = w; /*здесь w ∈ V – произвольно, СЛЕД [w] = w – означает, что Т = Ø;*/
3. for v ∈ V do    БЛЖ[v] = w;
4. While (F ≠ V) do 
5.     begin F = F ∪ {v(F)};
6.       СЛЕД [v(F)] = СЛЕД [pv1(F)]; СЛЕД [pv(F)] = v(F); 
                      /*т.е., добавить в Т ребра (pv(F), v(F) и (v(F), 
												p1v(F)) и удалить ребро (pv(F), p1v(F)), 
                       где через p1v(F), обозначена вершина, следующая за pv(F) в Т */

7.	     for v ∈ V do   
8.	         if c(v(F), v) < БЛЖ[v], then БЛЖ[v] = v(F);
9.	   еnd (5)
10 end.
```

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2052.png)

Разберем пример работы алгоритмов Ближайший сосед и Ближайшая вставка.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2053.png)

Предположим, что оба алгоритма начинают с вершины 1.

**Ближайший сосед.**

1
1-2
1-2-3
1-2-3
1-2-3-4

Вес полученного маршрута – 25.

**Ближайшая вставка**

1-1
1-2-1
1-2-3-1

Дальнейшее зависит от того, что выбрано в качестве проекции вершины 4 на множество F, состоящее из вершин 1, 2 и 3.

Если p4(F) = 1, то получается МК : 1-4-2-3-1 веса 29.
Если p4(F) = 2, то получается МК : 1-2-4-3-1 веса 26.
Если p4(F) = 3, то получается МК : 1-2-3-4-1 веса 25.

### Теорема (Розенталь, Штерн, Льюис, 1977 год).

Пусть А алгоритм Ближайшая вставка.
Тогда, для любого метрического графа $G$ справедливо неравенство
$|| А(G) || ≤ 2^*||Opt(G)||$.
т.е., алгоритм дает оценку точности 2 в классе метрических графов.

**Доказательство (А.Ипатов).**

В маршруте коммивояжера $А(G)$, построенном алгоритмом, удалим произвольное ребро. Получим граф $р^*$, являющийся деревом. Тогда $|| p^* || ≥ C$, где через С обозначен вес минимального остова исходного графа G. Следовательно, $|| p || ≥ C$. Более того, фактически доказано, что вес любого МК, в том числе и оптимального, не меньше чем $С$, где $С$ – вес минимального остова.

Пронумеруем все вершины попадающие в $А(G)$), получим последовательность 
$\{v_1 = w, v_2, …,v_n\}$. Стоимость МК $А(G)$ равна сумме стоимостей добавлений и удалений ребер. Пусть $s(v_i)$ означает стоимость добавления вершины $v_i$ в маршрут $А(G)$.

Тогда, справедливы равенства $|| А(G) || = \sum_{i=0}^ns(v_i)$;

где$\begin{cases}s(v_1) = 0\\s(vi) = c(v_i, pv_i(F)) + c(v_i, pv_i1(F) – c(pv_i(F),pv_i1(F))  \end{cases}$         (1)

(здесь вершина $v_i$ играет роль вершины $v(F)$, как она обозначена в алгоритме).

По неравенству треугольника имеем

$c(v_i, pv_i1(F)) ≤ c(v_i, pv_i(F)) + c(pvi(F),pv_i1(F))$                      (2)

Подставим неравенство (2) в (1), получим $s(v_i)$ = $2*c(v_i, pv_i(F))$.

Заметим теперь, что вершины vi являются вершинами растущего дерева в алгоритме Ярника, Прима, Дейкстры, а ребро ${ v_i, pv_i(F) }$ является ребром минимального остова.
Значит $|| А(G) || ≤ 2C$.

Отсюда, $\frac{|| А(G) ||}{||Opt(G)||} ≤ \frac{2C}{||Opt(G)||} ≤ 2$.

Теорема доказана.

### Теорема.

Алгоритм Ближайшая вставка имеет сложность $O(n^2)$.
**Доказательство**. 
В прошлом семестре, подробно разбирался алгоритм Ярника, Прима, Дейкстры, были введены необходимые структуры данных (в частности массив БЛЖ), чтобы получить сложность $О(n^2)$ так как, при незатейливой реализации, получается сложность $O(n^3)$. (Собственно именно это является заслугой Дейкстры; фактически именно он ввел понятие сложности алгоритма и предложил эффективную реализацию алгоритма Прима, как тогда называли этот алгоритм). Я не буду здесь воспроизводить то, что изложено ранее и сейчас является классикой. Подумайте сами или поройтесь в литературе.

Минимальный остов может являться хорошим приближением маршрута коммивояжера. На этой идее основан еще один алгоритм, с гарантированной оценкой сложности.
Понадобится

### Алгоритм Остовный обход

**Определение**. Пусть $G$ – Эйлеров граф и все вершины выписаны в том порядке, как они встречаются в Эйлеровом цикле $\{v_1, v_2, …, v_k\}$, где ребра образованы соседними вершинами.

Маршрут коммивояжера называется вписанным в Эйлеров, если каждая вершина, кроме первой, выписана один раз в том порядке, в котором она встречается в Эйлеровом маршруте, первая вершина встречается дважды, в начале и в конце списка.
Не формально изложим алгоритм Остовный обход

1. Построить минимальный остов $Т$ заданного графа, где $Т$ множество ребер.
2. В графе $(V, 2T)$ построить Эйлеров цикл $р$, заданный списком вершин и где граф с ребрами $2Т$ получен удвоением ребер, входящих в минимальный остов.
3. Построить маршрут коммивояжера $q$, вписанный в $p$.
4. Выдать МК $q$.

### Теорема.

Для произвольного метрического графа G, алгоритм Остовный обход гарантирует решение не более чем в два раза превосходящее оптимальное.

**Доказательство**. Отметим сразу, что степень каждой вершины в графе $(V,2T)$ четна, значит существует Эйлеров цикл $p$. Пусть он представлен списком вершин $\{v_1, v_2, …, v_k\}$. Пусть $v_i$ и $v_{i+1}$ две последовательные вершины в вписанном МК $q$, а в Эйлеровом цикле $р$ между ними стоят вершины $\{w_1, w_2, …,w_j\}$. Тогда из неравенства треугольника следует, что 
$с(v_i, v_{i+1}) ≤ c(v_1, w_1) + c(w_1, w_2) + … + c(w_j,v_{1+1})$.

Но левая часть этого неравенства входит в МК, а правая – в Эйлеров цикл.
Отсюда получаем неравенство $|| q || ≤ || p || = 2C$, где $С$ – вес минимального остова исходного графа $G$.

Остается вспомнить что для любого МК, в частности и для $Opt(G)$, верно неравенство
$С ≤ ||Opt(G)||.$ Отсюда и следует требуемое. Теорема доказана.

Иллюстрирует сказанное картинка

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2054.png)

Разберем пример работы алгоритма. Возьмем тот же граф, что и раньше

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2055.png)

Минимальным остовом будет множество ребер $\{1,2\}; \{2,3\}; \{3,4\}$.
Эйлеров цикл р: 1-2-3-4-3-2-1.
МК $q$, вписанный в $p: 1-2-3-4-1$, вес его равен 25.

### Теорема.

Алгоритм Остовный обход имеет сложность $O(n^2)$

**Доказательство**. Конечно, на первом шаге (построения минимального остова) надо применять алгоритм Ярника, Прима, Дейкстры, который имеет сложность $O(n^2)$. Построение графа $(V, 2T)$ имеет сложность $O(n$). Построение Эйлерова цикла - $O(m)$, но $m = 2(n – 1)$. Построить вписанный маршрут, это просто пробежаться один раз по списку вершин. Отсюда, получается окончательная сложность $O(n^2)$.

# Лекция 13.

## Стохастические Алгоритмы

Труднорешаемые задачи иногда неплохо решать с помощью вероятностных алгоритмов. Разберем этот подход на примере задачи коммивояжера.

Обозначим через $А$ алгоритм, который на входе получает МК, затем СЛУЧАЙНЫМ образом выбираются две вершины и переставляются местами.

Будем считать, что МК задается массивом $СЛЕД$, тогда работу алгоритма $А$ можно изобразить следующим образом (здесь изображен вход в алгоритм).

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2056.png)

Предположим, что переставляются вершины $v$ и $w$, здесь, через $v+$ и $w+$ обозначены вершины, следующие за $v$ и $w$ в МК, а через $v-$ и $w-$ их предшественники в МК.

Тогда вся перестановка заключается в том, что удаляются 4 ссылки $СЛЕД[v]$, $СЛЕД[v-]$, $СЛЕД[w-]$, $СЛЕД[w]$, а вместо них встают новые. Вся замена изображена ниже на рисунке.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2057.png)

Здесь, удаляемые ссылки изображены волнистой линией, а новые – синими стрелками, а те, с чем ничего не происходит остаются черными.

Вес нового маршрута тоже легко считается.

$$
||T|| = ||T|| + c(w-,v) + c(v,w+) + c(v-,w) + c(w,v+) - c(v-,v) - c(v,v+) - c(w-,w) - c(w,w+)
$$

Таким образом алгоритм $А$, переставляющий два элемента в МК имеет сложность $О(1)$, так как не зависит от размерности задачи.

Теперь можно предложить простой алгоритм для задачи коммивояжера. Изложу его не формально.
Входом является полный взвешенный граф, выходом – МК.

### Простой стохастический алгоритм

```pascal
1. Используя, какой-нибудь быстрый алгоритм, построить стартовый МК - p.
2. До тех пор пока не надоест
3. begin Построить А (р),
4. Если ||А (р)|| < ||p||, то положить р = А (р);
5. end
6. Выдать р
7. Конец.
```

Как понимать фразу «Используя, какой-нибудь быстрый алгоритм», построить стартовый МК?
Годится, например, алгоритм «Ближайший сосед». Особенно, если прогнать его много раз, меняя стартовую вершину, и затем выбрать наилучший.

Для реализации нового оператора «Пока не надоест» достаточно использовать любой из следующих методов.

1. Поставить счетчик, и выполнять названную процедуру столько раз, сколько захочется.
2. Поставить ограничение по времени.
3. Или использовать какой-нибудь другой способ.

Имеющиеся данные в литературе говорят, что итоговый результат, тем лучше, чем лучше стартовое решение. Обычно, этот алгоритм называют «2-окрестности».

Имеющиеся данные (не проверял) говорят о том, что алгоритм «3-окрестности» не дает существенного улучшения, так же не получается существенного улучшения, если пытаться переставляемые вершины, поставить наилучшим образом в текущий МК.

Слабым местом, приведенного алгоритма, является то, что он принимает новые решения, только если оно лучше старого. Алгоритм не позволяет обходить «локальные ямы». Можно привести следующий пример. Ниже нарисована возможная картинка, по оси абсцисс изображены последовательные МК, по оси ординат – их веса.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2058.png)

Здесь, если алгоритм попал в промежуток (1,4), то он уже никогда не попадет в промежуток (6,9) поскольку мешает бугорок в промежутке (4,6).

А между тем, еще в шестидесятые годы, специалисты по линейному программированию, при решении очень больших задач заметили, что иногда надо выбирать промежуточные решения, которые хуже, а результат получается лучше!

Устраняет этот недостаток алгоритм, называемый «Моделирование отжига». Появился этот метод, в применении к задачам дискретной оптимизации, где-то в конце восьмидесятых годов. А впервые он описан в 1953 году, в работе Н. Метрополиса в задачах физики.

Пусть состояние некоторой системы описывается энергией – $Е1$, при каком условии система переходит в состояние с энергией $Е2$?
Если $Е2 < Е1$, то всегда, а если $Е2 ≥ Е1$?

Оказывается, возможно и такое, переход возможен, но с вероятностью
$e^{-\frac{E1 – E2}{b}}$  , где $b$ – некоторый параметр, и, если $Е2 < E1$ (то есть, аргумент у функции $е$ меньше нуля), то вероятность считается равной единице. Для наглядности, приведу график функции $e^{-x}$

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2059.png)

Теперь всё готово, для изложения алгоритма моделирования отжига.
Пусть $Е$ обозначает вес каждого маршрута коммивояжера.
Выберем схему остывания: $E1 > E2 > … > En ≈ 0$.

### Алгоритм Моделирование отжига

```pascal
1. Используя, какой-нибудь быстрый алгоритм, построить стартовый МК - p.
2. Для всех i = 1 до n делать
3. begin До тех пор пока не надоест
4. begin Построить А (р);
5. Если ||А (р)|| < ||p||, то положить р = А (р);
6. Иначе, положить р = А (р) с вероятностью e - (||p|| -||A(p)||/ Ei
7. end; end
8. Выдать р.
9. Конец.
```

То есть вначале принимаются плохие варианты почти всегда, но затем они принимаются заметно реже. Можно сказать никогда.

Итак, в этом алгоритме, на каждом шаге монетка бросается два раза. Первый – при построении $А(р)$, второй – при выборе вероятности перехода.

Конечно, этот алгоритм достаточно сложный, надо хорошо подобрать схему остывания.

Почему этот алгоритм хорошо работает?
Объяснение одно.
В природе это работает, значит в математике тоже!

### Точные решения. Метод ветвей и границ

Разберу на примере ЗК.
Это метод получения точного решения путем разумного сокращения полного перебора.
Пусть $G$ – полный, взвешенный граф.
Будем анализировать дерево решений, которое будем считать ориентированным, двоичным.

Пусть $v$ – вершина в дереве решений, тогда через $v_0$ обозначим левого сына, а через $v_1$ – правого и через $М(v)$ обозначаем все МК, входящие в вершину $v$.

Пусть имеются алгоритмы

1. Алгоритм выбора ребра $е$ по которому левому сыну отвечают все МК содержащие ребро $е$, а 	правому – не содержащие $е$ (правило ветвления)
2. Алгоритм вычисления нижних границ маршрутов из $М(v)$, то есть, такого числа $f(v)$, что для любого МК $р$ из $М(v)$ выполняется неравенство $||p|| ≥ f(v)$ (правило границ).

**АЛГОРИТМ.**
Последовательно, начиная с вершины соответствующей всем МК, выбирать вершину с  наименьшей нижней границей и ветвить ее. Процесс продолжать до тех пор пока не будет найдена вершина $w$ с наименьшей нижней границей и $M(w)$ cостоит из одного МК, а для всех еще не ветвящихся вершин, нижняя граница не меньше чем $f(w)$.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2060.png)

# Лекция 14.

1. (Ветвление). Общий принцип: выбирать такое ребро е, чтобы нижняя граница правого сына была как можно  больше, чем у левого.
Годится такой метод: выбрать ребро, то есть, элемент в матрице весов так, чтобы сумма вторых элементов в этой матрице была как можно больше.
2. (Границы). Осуществить редукцию матрицы, соответствующей данной вершине. Тогда сумма всех констант, использованных при редукции и есть нижняя граница рассматриваемой вершины.

Какой сын лучше? Конечно левый, так как у левого матрица становится на единицу меньшей размерности, а у правого только на пересечении нужной строки и столбца становится бесконечность (то есть нельзя брать это ребро).

**Пример**.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2061.png)

По экспериментам, количество ветвей в дереве решений примерно $1,2^n$

### Метод ветвей и границ для игровых программ

На примере шахмат.

В основе лежит функция оценки позиции.
Пусть $а$ – это позиция. Положим
$f(a) = ∑\{x_k : k = 1, 2, …, 16\} - ∑ \{y_k : k = 1, 2, …, 16\}  + \phi$

Где   $∑\{x_k : k = 1, 2, …, 16\}$ - сумма своего материала,
$∑ \{y_k : k = 1, 2, …,16\}$ – сумма материала противника, φ – оценка позиции.

Главное здесь, то что удается  $\phi$  представить в виде числа.
Конечно $\phi$ – играет ключевую роль.
Устанавливается глубина расчета позиции.

В сильных программах, оно равно 13, но динамически может меняться после взятий пешки или фигуры и после шахов.
Задача: сделать наилучший ход.

![Untitled](/Лекции%20по%20комбинаторным%20алгоритмам/Фото/Untitled%2062.png)

---

Строится дерево поиска на заданную глубину.
( на рисунке глубина просмотра равна 5 )

1. На последнем уровне, из вершины предпоследнего уровня, строятся все сыновья.
2. Для каждой вершины последнего уровня считается величина $f(a)$.
3. Мы не дураки и выберем вершину с $max \{f(a)\}$ $\alpha$ - отсечение
4. Противник тоже не дурак, он выберет вершину с $min\{f(a)\}$, $\beta$ - отсечение.
Так постепенно добираемся до корня, получаем оценку позиции в корне и делаем ход.

Всё.
